{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucaslyon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa\n",
    "#import librosa.display\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.pyplot import specgram\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Importing Data for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .DS_Store\n",
      "1 Actor_01\n",
      "2 Actor_02\n",
      "3 Actor_03\n",
      "4 Actor_04\n",
      "5 Actor_05\n",
      "6 Actor_06\n",
      "7 Actor_07\n",
      "8 Actor_08\n",
      "9 Actor_09\n",
      "10 Actor_10\n",
      "11 Actor_11\n",
      "12 Actor_12\n",
      "13 Actor_13\n",
      "14 Actor_14\n",
      "15 Actor_15\n",
      "16 Actor_16\n",
      "17 Actor_17\n",
      "18 Actor_18\n",
      "19 Actor_19\n",
      "20 Actor_20\n",
      "21 Actor_21\n",
      "22 Actor_22\n",
      "23 Actor_23\n",
      "24 Actor_24\n"
     ]
    }
   ],
   "source": [
    "actorlist = os.listdir('Audio')\n",
    "mydir = 'Audio/'\n",
    "mylist = os.listdir(mydir)\n",
    "actorlist.sort()\n",
    "\n",
    "feeling_list=[]\n",
    "mydir = 'Audio/'\n",
    "for actor in actorlist:\n",
    "    try:\n",
    "        mylist = os.listdir(mydir+actor)\n",
    "        mylist.sort()\n",
    "        for item in mylist:\n",
    "            \n",
    "            #neutral\n",
    "            if item[6:-16]=='01' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(5)\n",
    "            elif item[6:-16]=='01' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(5)\n",
    "            #calm\n",
    "            if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(5)\n",
    "            elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(5)\n",
    "            #happy\n",
    "            elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(3)\n",
    "            elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(3)\n",
    "            #sad\n",
    "            elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(4)\n",
    "            elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(4)\n",
    "            #angry\n",
    "            elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(0)\n",
    "            elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(0)\n",
    "            #fear\n",
    "            elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(1)\n",
    "            elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(1)\n",
    "            #disgust\n",
    "            if item[6:-16]=='07' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(2)\n",
    "            elif item[6:-16]=='07' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(2)\n",
    "            #surprise\n",
    "            if item[6:-16]=='08' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(6)\n",
    "            elif item[6:-16]=='08' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(6)\n",
    "                \n",
    "    except: pass\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#labels = pd.DataFrame(feeling_list)\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,actor in enumerate(actorlist):\n",
    "    print(index, actor)\n",
    "    try:\n",
    "        recordinglist = os.listdir('Audio/'+actor)\n",
    "        for index, recording in enumerate(recordinglist):\n",
    "            X, sample_rate = librosa.load('Audio/'+actor+'/'+recording, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "            sample_rate = np.array(sample_rate)\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                                sr=sample_rate, \n",
    "                                                n_mfcc=40),\n",
    "                            axis=0)\n",
    "            feature = mfccs\n",
    "            df.loc[bookmark] = [feature]\n",
    "            bookmark=bookmark+1\n",
    "    except: pass\n",
    "\n",
    "actorDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "\n",
    "#labeledDf = pd.concat([featuresDf, labels], axis=1)\n",
    "\n",
    "#named = labeledDf.rename(index=str, columns={\"0\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/fear/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=40),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "fearDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#fearDf['label'] = \"fear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/angry/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=40),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "angryDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#angryDf['label'] = \"angry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/disgust/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=40),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "disgustDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#disgustDf['label'] = \"disgust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/happy/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "happyDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#happyDf['label'] = \"happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/neutral/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "neutralDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#neutralDf['label'] = \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/surprise/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "surpriseDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#surpriseDf['label'] = \"surprise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/sad/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "sadDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#sadDf['label'] = \"sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/DC/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "dc_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        dc_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        dc_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        dc_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        dc_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        dc_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        dc_feeling_list.append('sad')\n",
    "    else: dc_feeling_list.append('surprise')\n",
    "    \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "#labels = pd.DataFrame(dc_feeling_list)\n",
    "dcDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#dcDf = pd.concat([dcDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/JE/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "je_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        je_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        je_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        je_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        je_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        je_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        je_feeling_list.append('sad')\n",
    "    else: je_feeling_list.append('surprise')\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "jeDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(je_feeling_list)\n",
    "#jeDf = pd.concat([jeDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/JK/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "jk_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        jk_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        jk_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        jk_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        jk_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        jk_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        jk_feeling_list.append('sad')\n",
    "    else: jk_feeling_list.append('surprise')\n",
    "    \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "jkDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(jk_feeling_list)\n",
    "#jkDf = pd.concat([jkDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/KL/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "kl_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        kl_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        kl_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        kl_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        kl_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        kl_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        kl_feeling_list.append('sad')\n",
    "    else: kl_feeling_list.append('surprise')\n",
    "        \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "klDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(kl_feeling_list)\n",
    "#klDf = pd.concat([klDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioWAV/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "wav_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "        emotion = file[9:12] \n",
    "        \n",
    "        if emotion == \"ANG\":\n",
    "            wav_feeling_list.append(\"angry\")\n",
    "        elif emotion == \"DIS\":\n",
    "            wav_feeling_list.append(\"disgust\")\n",
    "        elif emotion == \"FEA\":\n",
    "            wav_feeling_list.append(\"fear\")\n",
    "        elif emotion == \"HAP\":\n",
    "            wav_feeling_list.append(\"happy\")\n",
    "        elif emotion == \"NEU\":\n",
    "            wav_feeling_list.append(\"neutral\")\n",
    "        elif emotion == \"SAD\":\n",
    "            wav_feeling_list.append(\"sad\")\n",
    "        else:\n",
    "            print(\"      \", emotion)\n",
    "    except:\n",
    "        pass\n",
    "wavDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labelsDf = pd.DataFrame(feeling_list)\n",
    "#wavDf = pd.concat([wavDf, labelsDf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/emodb/wav\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "emo_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=40),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "        emotion = file[5]\n",
    "        if emotion == 'A':\n",
    "            emo_feeling_list.append(\"fear\")\n",
    "        elif emotion == 'W':\n",
    "            emo_feeling_list.append(\"angry\")\n",
    "        elif emotion == 'L':\n",
    "            emo_feeling_list.append(\"bored\")\n",
    "        elif emotion == 'E':\n",
    "            emo_feeling_list.append(\"disgust\")\n",
    "        elif emotion == 'F':\n",
    "            emo_feeling_list.append(\"happy\")\n",
    "        elif emotion == 'T':\n",
    "            emo_feeling_list.append(\"sad\")\n",
    "        elif emotion == 'N':\n",
    "            emo_feeling_list.append(\"neutral\")\n",
    "        else:\n",
    "            print(\"error\", emotion)\n",
    "    except:\n",
    "        pass\n",
    "emoDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labelDf = pd.DataFrame(feeling_list)\n",
    "#emoDf = pd.concat([emoDf, labelDf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat2 = pd.concat([dcDf,jeDf, jkDf, klDf])\n",
    "concatenatedDf = pd.concat([angryDf, fearDf, disgustDf, happyDf, sadDf, neutralDf, surpriseDf, concat2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a list of emotion labels for each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_feeling_list = []\n",
    "for file in range(len(angryDf)):\n",
    "    compiled_feeling_list.append(0)\n",
    "for file in range(len(fearDf)):\n",
    "    compiled_feeling_list.append(1)\n",
    "for file in range(len(disgustDf)):\n",
    "    compiled_feeling_list.append(2)\n",
    "for file in range(len(happyDf)):\n",
    "    compiled_feeling_list.append(3)\n",
    "for file in range(len(sadDf)):\n",
    "    compiled_feeling_list.append(4)\n",
    "for file in range(len(neutralDf)):\n",
    "    compiled_feeling_list.append(5)\n",
    "for file in range(len(surpriseDf)):\n",
    "    compiled_feeling_list.append(6)\n",
    "\n",
    "dcjejkkl_feeling_list = dc_feeling_list + je_feeling_list + jk_feeling_list + kl_feeling_list\n",
    "for emo in range(len(dcjejkkl_feeling_list)):\n",
    "    if dcjejkkl_feeling_list[emo] == \"angry\":\n",
    "        compiled_feeling_list.append(0)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"fear\":\n",
    "        compiled_feeling_list.append(1)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"disgust\":\n",
    "        compiled_feeling_list.append(2)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"happy\":\n",
    "        compiled_feeling_list.append(3)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"sad\":\n",
    "        compiled_feeling_list.append(4)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"neutral\":\n",
    "        compiled_feeling_list.append(5)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"surprise\":\n",
    "        compiled_feeling_list.append(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pandas DataFrame with emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feeling_list) == len(actorDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_feeling_list += feeling_list\n",
    "concatenatedDf = pd.concat([concatenatedDf, actorDf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelDf = pd.DataFrame(compiled_feeling_list)\n",
    "\n",
    "concatenatedDf = concatenatedDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf = pd.concat([concatenatedDf, labelDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf = concatenatedDf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exported the labeled Pandas DataFrame for easier import of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf.to_csv(\"9_29_2018_2_00_pm_emotions_and_speakers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3924, 216)\n",
      "3924 train samples\n",
      "439 test samples\n"
     ]
    }
   ],
   "source": [
    "emotionsDf = pd.read_csv(\"9_29_2018_12_25_pm_emotions_and_speakers.csv\")\n",
    "#emotionsDf = emotionsDf.drop('Unnamed: 0', 1)\n",
    "from sklearn.utils import shuffle\n",
    "shuffledDf = shuffle(emotionsDf)\n",
    "\n",
    "divider = np.random.rand(len(shuffledDf)) < 0.9\n",
    "train = shuffledDf[divider]\n",
    "test = shuffledDf[~divider]\n",
    "\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabels = train.iloc[:, -1:]\n",
    "\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabels = test.iloc[:, -1:]\n",
    "\n",
    "x_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabels)\n",
    "x_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabels)\n",
    "\n",
    "#flattening the arrays\n",
    "y_train = np.hstack(y_train)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "#convert class vectors to binary class matrices.\n",
    "num_classes = 7\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train = np.expand_dims(x_train, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, 5, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(256, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adadelta()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt6Architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3924 samples, validate on 439 samples\n",
      "Epoch 1/100\n",
      "3924/3924 [==============================] - 16s 4ms/step - loss: 2.0176 - acc: 0.1414 - val_loss: 1.9456 - val_acc: 0.1435\n",
      "Epoch 2/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9515 - acc: 0.1473 - val_loss: 1.9343 - val_acc: 0.1595\n",
      "Epoch 3/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9493 - acc: 0.1460 - val_loss: 1.9455 - val_acc: 0.1435\n",
      "Epoch 4/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9461 - acc: 0.1414 - val_loss: 1.9454 - val_acc: 0.1458\n",
      "Epoch 5/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9476 - acc: 0.1391 - val_loss: 1.9454 - val_acc: 0.1458\n",
      "Epoch 6/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1417 - val_loss: 1.9454 - val_acc: 0.1458\n",
      "Epoch 7/100\n",
      "3924/3924 [==============================] - 14s 3ms/step - loss: 1.9455 - acc: 0.1442 - val_loss: 1.9454 - val_acc: 0.1458\n",
      "Epoch 8/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9456 - acc: 0.1476 - val_loss: 1.9454 - val_acc: 0.1458\n",
      "Epoch 9/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1468 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 10/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1478 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 11/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1470 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 12/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 13/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1450 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 14/100\n",
      "3924/3924 [==============================] - 14s 3ms/step - loss: 1.9455 - acc: 0.1476 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 15/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 16/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1470 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 17/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 18/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 19/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 20/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1473 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 21/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1488 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 22/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1455 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 23/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 24/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 25/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9454 - acc: 0.1468 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 26/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.9456 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 27/100\n",
      "3924/3924 [==============================] - 9s 2ms/step - loss: 1.9466 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 28/100\n",
      "3924/3924 [==============================] - 10s 2ms/step - loss: 1.9457 - acc: 0.1493 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 29/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.9456 - acc: 0.1473 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 30/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 31/100\n",
      "3924/3924 [==============================] - 10s 2ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 32/100\n",
      "3924/3924 [==============================] - 10s 2ms/step - loss: 1.9455 - acc: 0.1468 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 33/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.9459 - acc: 0.1402 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 34/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9454 - acc: 0.1491 - val_loss: 1.9455 - val_acc: 0.1458\n",
      "Epoch 35/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 36/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9455 - acc: 0.1488 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 37/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1491 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 38/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9455 - acc: 0.1453 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 39/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.9462 - acc: 0.1501 - val_loss: 1.9456 - val_acc: 0.1458\n",
      "Epoch 40/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.9449 - acc: 0.1521 - val_loss: 1.9450 - val_acc: 0.1481\n",
      "Epoch 41/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.9342 - acc: 0.1682 - val_loss: 1.9120 - val_acc: 0.1595\n",
      "Epoch 42/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.8997 - acc: 0.1812 - val_loss: 1.8840 - val_acc: 0.1845\n",
      "Epoch 43/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.8901 - acc: 0.1817 - val_loss: 1.8688 - val_acc: 0.2210\n",
      "Epoch 44/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.8804 - acc: 0.1909 - val_loss: 1.8166 - val_acc: 0.2460\n",
      "Epoch 45/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.8435 - acc: 0.1978 - val_loss: 1.7325 - val_acc: 0.2460\n",
      "Epoch 46/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.8001 - acc: 0.2225 - val_loss: 1.6729 - val_acc: 0.2961\n",
      "Epoch 47/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.7791 - acc: 0.2334 - val_loss: 1.6661 - val_acc: 0.3121\n",
      "Epoch 48/100\n",
      "3924/3924 [==============================] - 15s 4ms/step - loss: 1.7542 - acc: 0.2424 - val_loss: 1.6596 - val_acc: 0.3212\n",
      "Epoch 49/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.7422 - acc: 0.2485 - val_loss: 1.6229 - val_acc: 0.3554\n",
      "Epoch 50/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.6943 - acc: 0.2745 - val_loss: 1.6120 - val_acc: 0.3531\n",
      "Epoch 51/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.6598 - acc: 0.2895 - val_loss: 1.5534 - val_acc: 0.4191\n",
      "Epoch 52/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.6394 - acc: 0.2926 - val_loss: 1.5317 - val_acc: 0.4169\n",
      "Epoch 53/100\n",
      "3924/3924 [==============================] - 16s 4ms/step - loss: 1.6177 - acc: 0.3101 - val_loss: 1.5361 - val_acc: 0.4237\n",
      "Epoch 54/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.5970 - acc: 0.3168 - val_loss: 1.4880 - val_acc: 0.4305\n",
      "Epoch 55/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.5721 - acc: 0.3300 - val_loss: 1.4994 - val_acc: 0.4396\n",
      "Epoch 56/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.5355 - acc: 0.3425 - val_loss: 1.4341 - val_acc: 0.4533\n",
      "Epoch 57/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.5217 - acc: 0.3629 - val_loss: 1.4199 - val_acc: 0.4715\n",
      "Epoch 58/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.5066 - acc: 0.3616 - val_loss: 1.4067 - val_acc: 0.4738\n",
      "Epoch 59/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.4771 - acc: 0.3713 - val_loss: 1.4267 - val_acc: 0.4624\n",
      "Epoch 60/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.4737 - acc: 0.3858 - val_loss: 1.3678 - val_acc: 0.4761\n",
      "Epoch 61/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.4742 - acc: 0.3797 - val_loss: 1.3607 - val_acc: 0.4647\n",
      "Epoch 62/100\n",
      "3924/3924 [==============================] - 14s 3ms/step - loss: 1.4726 - acc: 0.3790 - val_loss: 1.4218 - val_acc: 0.4670\n",
      "Epoch 63/100\n",
      "3924/3924 [==============================] - 13s 3ms/step - loss: 1.4385 - acc: 0.3940 - val_loss: 1.3417 - val_acc: 0.4875\n",
      "Epoch 64/100\n",
      "3924/3924 [==============================] - 14s 3ms/step - loss: 1.4390 - acc: 0.4006 - val_loss: 1.3435 - val_acc: 0.4692\n",
      "Epoch 65/100\n",
      "3924/3924 [==============================] - 14s 4ms/step - loss: 1.4145 - acc: 0.4131 - val_loss: 1.3189 - val_acc: 0.4829\n",
      "Epoch 66/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.4093 - acc: 0.4090 - val_loss: 1.3205 - val_acc: 0.4784\n",
      "Epoch 67/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.3860 - acc: 0.4218 - val_loss: 1.2965 - val_acc: 0.4920\n",
      "Epoch 68/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.3848 - acc: 0.4241 - val_loss: 1.3250 - val_acc: 0.4920\n",
      "Epoch 69/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.3940 - acc: 0.4202 - val_loss: 1.3168 - val_acc: 0.4943\n",
      "Epoch 70/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3522 - acc: 0.4304 - val_loss: 1.2690 - val_acc: 0.5011\n",
      "Epoch 71/100\n",
      "3924/3924 [==============================] - 12s 3ms/step - loss: 1.3739 - acc: 0.4345 - val_loss: 1.3080 - val_acc: 0.4943\n",
      "Epoch 72/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3611 - acc: 0.4422 - val_loss: 1.2993 - val_acc: 0.5125\n",
      "Epoch 73/100\n",
      "3924/3924 [==============================] - 222s 57ms/step - loss: 1.3698 - acc: 0.4343 - val_loss: 1.3101 - val_acc: 0.5080\n",
      "Epoch 74/100\n",
      "3924/3924 [==============================] - 25s 6ms/step - loss: 1.3647 - acc: 0.4365 - val_loss: 1.2690 - val_acc: 0.5034\n",
      "Epoch 75/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3461 - acc: 0.4406 - val_loss: 1.2758 - val_acc: 0.5353\n",
      "Epoch 76/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3525 - acc: 0.4337 - val_loss: 1.2700 - val_acc: 0.5194\n",
      "Epoch 77/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3330 - acc: 0.4424 - val_loss: 1.2664 - val_acc: 0.5080\n",
      "Epoch 78/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3401 - acc: 0.4401 - val_loss: 1.2500 - val_acc: 0.5262\n",
      "Epoch 79/100\n",
      "3924/3924 [==============================] - 23s 6ms/step - loss: 1.3464 - acc: 0.4355 - val_loss: 1.3027 - val_acc: 0.4897\n",
      "Epoch 81/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3255 - acc: 0.4442 - val_loss: 1.2512 - val_acc: 0.5308\n",
      "Epoch 82/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3327 - acc: 0.4467 - val_loss: 1.2642 - val_acc: 0.5239\n",
      "Epoch 83/100\n",
      "3924/3924 [==============================] - 387s 99ms/step - loss: 1.3308 - acc: 0.4411 - val_loss: 1.2562 - val_acc: 0.5216\n",
      "Epoch 84/100\n",
      "3924/3924 [==============================] - 23s 6ms/step - loss: 1.3209 - acc: 0.4424 - val_loss: 1.2838 - val_acc: 0.5125\n",
      "Epoch 85/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3193 - acc: 0.4452 - val_loss: 1.2910 - val_acc: 0.5216\n",
      "Epoch 86/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3123 - acc: 0.4516 - val_loss: 1.2654 - val_acc: 0.5353\n",
      "Epoch 87/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3147 - acc: 0.4501 - val_loss: 1.2656 - val_acc: 0.5194\n",
      "Epoch 88/100\n",
      "3924/3924 [==============================] - 230s 59ms/step - loss: 1.3064 - acc: 0.4503 - val_loss: 1.2716 - val_acc: 0.5216\n",
      "Epoch 89/100\n",
      "3924/3924 [==============================] - 23s 6ms/step - loss: 1.3086 - acc: 0.4488 - val_loss: 1.2767 - val_acc: 0.5308\n",
      "Epoch 90/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.2989 - acc: 0.4595 - val_loss: 1.2501 - val_acc: 0.5330\n",
      "Epoch 91/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3074 - acc: 0.4488 - val_loss: 1.2970 - val_acc: 0.5034\n",
      "Epoch 92/100\n",
      "3924/3924 [==============================] - 93s 24ms/step - loss: 1.2975 - acc: 0.4587 - val_loss: 1.2522 - val_acc: 0.5399\n",
      "Epoch 93/100\n",
      "3924/3924 [==============================] - 23s 6ms/step - loss: 1.3197 - acc: 0.4531 - val_loss: 1.2578 - val_acc: 0.5194\n",
      "Epoch 94/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.3161 - acc: 0.4526 - val_loss: 1.3071 - val_acc: 0.5103\n",
      "Epoch 95/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.2903 - acc: 0.4587 - val_loss: 1.3094 - val_acc: 0.5216\n",
      "Epoch 96/100\n",
      "3924/3924 [==============================] - 11s 3ms/step - loss: 1.2964 - acc: 0.4661 - val_loss: 1.2910 - val_acc: 0.5011\n",
      "Epoch 97/100\n",
      "3924/3924 [==============================] - 320s 81ms/step - loss: 1.3015 - acc: 0.4592 - val_loss: 1.2521 - val_acc: 0.5239\n",
      "Epoch 98/100\n",
      "3924/3924 [==============================] - 23s 6ms/step - loss: 1.2842 - acc: 0.4661 - val_loss: 1.2354 - val_acc: 0.5330\n",
      "Epoch 99/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.3012 - acc: 0.4498 - val_loss: 1.2758 - val_acc: 0.5216\n",
      "Epoch 100/100\n",
      "3924/3924 [==============================] - 10s 3ms/step - loss: 1.2961 - acc: 0.4551 - val_loss: 1.3007 - val_acc: 0.5376\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "cnnhistory = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(cnnhistory.history['acc'])\n",
    "# plt.plot(cnnhistory.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.savefig(\"Attempt6Acc.png\")\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"Attempt6Loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load(\"test_sample_d.wav\", res_type='kaiser_fast',duration=5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature0 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_a.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature1 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_s.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature2 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_a_2.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature3 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_surprise.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature4 = mfccs\n",
    "\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_a_3.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature5 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_s_2.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature6 = mfccs\n",
    "\n",
    "\n",
    "feature0 = np.pad(feature0, (0, 216-feature0.shape[0]), 'constant')\n",
    "feature0 = feature0.reshape(1, 216, 1)\n",
    "\n",
    "feature1 = np.pad(feature1, (0, 216-feature1.shape[0]), 'constant')\n",
    "feature1 = feature1.reshape(1, 216, 1)\n",
    "\n",
    "feature2 = np.pad(feature2, (0, 216-feature2.shape[0]), 'constant')\n",
    "feature2 = feature2.reshape(1, 216, 1)\n",
    "\n",
    "feature3 = np.pad(feature3, (0, 216-feature3.shape[0]), 'constant')\n",
    "feature3 = feature3.reshape(1, 216, 1)\n",
    "\n",
    "feature4 = np.pad(feature4, (0, 216-feature4.shape[0]), 'constant')\n",
    "feature4 = feature4.reshape(1,216,1)\n",
    "\n",
    "feature5 = np.pad(feature5, (0, 216-feature5.shape[0]), 'constant')\n",
    "feature5 = feature5.reshape(1,216,1)\n",
    "\n",
    "feature6 = np.pad(feature6, (0, 216-feature6.shape[0]), 'constant')\n",
    "feature6 = feature6.reshape(1,216,1)\n",
    "\n",
    "# feats = [feature0, feature1]\n",
    "# 0 angry\n",
    "# 1 fear\n",
    "# 2 disgust\n",
    "# 3 happy\n",
    "# 4 sad\n",
    "# 5 neutral\n",
    "# 6 surprise\n",
    "\n",
    "\n",
    "prediction0 = model.predict_classes(feature0)\n",
    "prediction1 = model.predict_classes(feature1)\n",
    "prediction2 = model.predict_classes(feature2)\n",
    "prediction3 = model.predict_classes(feature3)\n",
    "prediction4 = model.predict_classes(feature4)\n",
    "prediction5 = model.predict_classes(feature5)\n",
    "prediction6 = model.predict_classes(feature6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    [2]\n"
     ]
    }
   ],
   "source": [
    "print(\".   \", prediction6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

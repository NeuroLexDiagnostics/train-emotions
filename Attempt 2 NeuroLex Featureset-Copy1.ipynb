{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "#import librosa.display\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angryFiles = os.listdir('emotion_train_set/angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['379_4.wav', '441_3.json', '845_2.wav', '1986_5.wav', '210_3.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angryFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disgustFiles = os.listdir('emotion_train_set/disgust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fearFiles = os.listdir('emotion_train_set/fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "happyFiles = os.listdir('emotion_train_set/happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutralFiles = os.listdir('emotion_train_set/neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sadFiles = os.listdir('emotion_train_set/sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surpriseFiles = os.listdir('emotion_train_set/surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angryFiles.sort()\n",
    "disgustFiles.sort()\n",
    "fearFiles.sort()\n",
    "happyFiles.sort()\n",
    "neutralFiles.sort()\n",
    "sadFiles.sort()\n",
    "surpriseFiles.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "angryJSONFiles = os.listdir('emotion_train_set/angry')\n",
    "angryJSONFiles.sort()\n",
    "angryData=[]\n",
    "for file in angryJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/angry/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            angryData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "disgustJSONFiles = os.listdir('emotion_train_set/disgust')\n",
    "disgustJSONFiles.sort()\n",
    "disgustData=[]\n",
    "for file in disgustJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/disgust/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            disgustData.append(d['features'])\n",
    "    except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fearJSONFiles = os.listdir('emotion_train_set/fear')\n",
    "fearJSONFiles.sort()\n",
    "fearData=[]\n",
    "for file in fearJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/fear/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            fearData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "happyJSONFiles = os.listdir('emotion_train_set/happy')\n",
    "happyJSONFiles.sort()\n",
    "happyData=[]\n",
    "for file in happyJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/happy/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            happyData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutralJSONFiles = os.listdir('emotion_train_set/neutral')\n",
    "neutralJSONFiles.sort()\n",
    "neutralData=[]\n",
    "for file in neutralJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/neutral/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            neutralData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sadJSONFiles = os.listdir('emotion_train_set/sad')\n",
    "sadJSONFiles.sort()\n",
    "sadData=[]\n",
    "for file in sadJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/sad/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            sadData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surpriseJSONFiles = os.listdir('emotion_train_set/surprise')\n",
    "surpriseJSONFiles.sort()\n",
    "surpriseData=[]\n",
    "for file in surpriseJSONFiles:\n",
    "    try:\n",
    "        with open('emotion_train_set/surprise/'+file) as json_data:\n",
    "            d = json.load(json_data)\n",
    "            surpriseData.append(d['features'])\n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angryDf = pd.DataFrame(angryData)\n",
    "disgustDf = pd.DataFrame(disgustData)\n",
    "fearDf = pd.DataFrame(fearData)\n",
    "happyDf = pd.DataFrame(happyData)\n",
    "neutralDf = pd.DataFrame(neutralData)\n",
    "sadDf = pd.DataFrame(sadData)\n",
    "surpriseDf = pd.DataFrame(surpriseData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angryDf['label'] = 'angry'\n",
    "disgustDf['label'] = 'disgust'\n",
    "fearDf['label'] = 'fear'\n",
    "happyDf['label'] = 'happy'\n",
    "neutralDf['label'] = 'neutral'\n",
    "sadDf['label'] = 'sad'\n",
    "surpriseDf['label'] = 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotionsDf = pd.concat([angryDf, disgustDf, fearDf, happyDf, neutralDf, sadDf, surpriseDf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "shuffledEmotionsDf = shuffle(emotionsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "divider = np.random.rand(len(shuffledEmotionsDf)) < 0.85\n",
    "train = shuffledEmotionsDf[divider]\n",
    "test = shuffledEmotionsDf[~divider]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucaslyon/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5707, 272)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(272,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 272, 128)          768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 272, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 272, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 272, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 272, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 34, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 34, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 34, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 34, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 34, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4352)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 30471     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 441,479\n",
      "Trainable params: 441,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences')\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import mean_squared_error\n",
    "model.compile(loss=mean_squared_error, optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5707 samples, validate on 1013 samples\n",
      "Epoch 1/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1375 - acc: 0.2159 - val_loss: 0.1147 - val_acc: 0.2646\n",
      "Epoch 2/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1248 - acc: 0.2308 - val_loss: 0.1139 - val_acc: 0.2932\n",
      "Epoch 3/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1200 - acc: 0.2457 - val_loss: 0.1126 - val_acc: 0.3119\n",
      "Epoch 4/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1175 - acc: 0.2581 - val_loss: 0.1121 - val_acc: 0.3021\n",
      "Epoch 5/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1164 - acc: 0.2592 - val_loss: 0.1120 - val_acc: 0.3011\n",
      "Epoch 6/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1157 - acc: 0.2637 - val_loss: 0.1117 - val_acc: 0.3119\n",
      "Epoch 7/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1143 - acc: 0.2903 - val_loss: 0.1125 - val_acc: 0.2922\n",
      "Epoch 8/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1142 - acc: 0.2854 - val_loss: 0.1115 - val_acc: 0.3258\n",
      "Epoch 9/100\n",
      "5707/5707 [==============================] - 29s 5ms/step - loss: 0.1138 - acc: 0.2895 - val_loss: 0.1121 - val_acc: 0.2705\n",
      "Epoch 10/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1137 - acc: 0.2896 - val_loss: 0.1108 - val_acc: 0.3327\n",
      "Epoch 11/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1130 - acc: 0.2931 - val_loss: 0.1110 - val_acc: 0.3179\n",
      "Epoch 12/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1127 - acc: 0.3038 - val_loss: 0.1109 - val_acc: 0.3258\n",
      "Epoch 13/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1129 - acc: 0.2989 - val_loss: 0.1106 - val_acc: 0.3258\n",
      "Epoch 14/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1122 - acc: 0.3131 - val_loss: 0.1103 - val_acc: 0.3356\n",
      "Epoch 15/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1121 - acc: 0.3107 - val_loss: 0.1107 - val_acc: 0.3159\n",
      "Epoch 16/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1118 - acc: 0.3103 - val_loss: 0.1107 - val_acc: 0.3277\n",
      "Epoch 17/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1119 - acc: 0.3121 - val_loss: 0.1104 - val_acc: 0.3248\n",
      "Epoch 18/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1119 - acc: 0.3101 - val_loss: 0.1103 - val_acc: 0.3149\n",
      "Epoch 19/100\n",
      "5707/5707 [==============================] - 29s 5ms/step - loss: 0.1117 - acc: 0.3108 - val_loss: 0.1100 - val_acc: 0.3346\n",
      "Epoch 20/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1113 - acc: 0.3219 - val_loss: 0.1101 - val_acc: 0.3327\n",
      "Epoch 21/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1115 - acc: 0.3166 - val_loss: 0.1097 - val_acc: 0.3337\n",
      "Epoch 22/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1113 - acc: 0.3201 - val_loss: 0.1098 - val_acc: 0.3258\n",
      "Epoch 23/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1107 - acc: 0.3291 - val_loss: 0.1095 - val_acc: 0.3386\n",
      "Epoch 24/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1109 - acc: 0.3256 - val_loss: 0.1094 - val_acc: 0.3287\n",
      "Epoch 25/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1107 - acc: 0.3264 - val_loss: 0.1096 - val_acc: 0.3346\n",
      "Epoch 26/100\n",
      "5707/5707 [==============================] - 26s 4ms/step - loss: 0.1106 - acc: 0.3231 - val_loss: 0.1096 - val_acc: 0.3337\n",
      "Epoch 27/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1106 - acc: 0.3291 - val_loss: 0.1099 - val_acc: 0.3159\n",
      "Epoch 28/100\n",
      "5707/5707 [==============================] - 23s 4ms/step - loss: 0.1100 - acc: 0.3375 - val_loss: 0.1107 - val_acc: 0.3258\n",
      "Epoch 29/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1102 - acc: 0.3363 - val_loss: 0.1092 - val_acc: 0.3455\n",
      "Epoch 30/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1101 - acc: 0.3352 - val_loss: 0.1093 - val_acc: 0.3317\n",
      "Epoch 31/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1102 - acc: 0.3384 - val_loss: 0.1093 - val_acc: 0.3297\n",
      "Epoch 32/100\n",
      "5707/5707 [==============================] - 24s 4ms/step - loss: 0.1101 - acc: 0.3298 - val_loss: 0.1101 - val_acc: 0.3248\n",
      "Epoch 33/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1098 - acc: 0.3327 - val_loss: 0.1093 - val_acc: 0.3396\n",
      "Epoch 34/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1096 - acc: 0.3343 - val_loss: 0.1095 - val_acc: 0.3248\n",
      "Epoch 35/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1097 - acc: 0.3424 - val_loss: 0.1098 - val_acc: 0.3268\n",
      "Epoch 36/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1100 - acc: 0.3364 - val_loss: 0.1098 - val_acc: 0.3337\n",
      "Epoch 37/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1094 - acc: 0.3420 - val_loss: 0.1094 - val_acc: 0.3455\n",
      "Epoch 38/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1097 - acc: 0.3343 - val_loss: 0.1089 - val_acc: 0.3455\n",
      "Epoch 39/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1094 - acc: 0.3371 - val_loss: 0.1091 - val_acc: 0.3386\n",
      "Epoch 40/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1092 - acc: 0.3410 - val_loss: 0.1103 - val_acc: 0.3129\n",
      "Epoch 41/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1090 - acc: 0.3448 - val_loss: 0.1092 - val_acc: 0.3445\n",
      "Epoch 42/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1090 - acc: 0.3445 - val_loss: 0.1088 - val_acc: 0.3425\n",
      "Epoch 43/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1090 - acc: 0.3466 - val_loss: 0.1089 - val_acc: 0.3514\n",
      "Epoch 44/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1086 - acc: 0.3473 - val_loss: 0.1092 - val_acc: 0.3238\n",
      "Epoch 45/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1093 - acc: 0.3419 - val_loss: 0.1089 - val_acc: 0.3445\n",
      "Epoch 46/100\n",
      "5707/5707 [==============================] - 29s 5ms/step - loss: 0.1088 - acc: 0.3422 - val_loss: 0.1085 - val_acc: 0.3514\n",
      "Epoch 47/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1088 - acc: 0.3452 - val_loss: 0.1089 - val_acc: 0.3475\n",
      "Epoch 48/100\n",
      "5707/5707 [==============================] - 29s 5ms/step - loss: 0.1086 - acc: 0.3518 - val_loss: 0.1086 - val_acc: 0.3435\n",
      "Epoch 49/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1087 - acc: 0.3518 - val_loss: 0.1092 - val_acc: 0.3425\n",
      "Epoch 50/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1085 - acc: 0.3533 - val_loss: 0.1088 - val_acc: 0.3495\n",
      "Epoch 51/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1084 - acc: 0.3559 - val_loss: 0.1089 - val_acc: 0.3554\n",
      "Epoch 52/100\n",
      "5707/5707 [==============================] - 39s 7ms/step - loss: 0.1084 - acc: 0.3490 - val_loss: 0.1091 - val_acc: 0.3346\n",
      "Epoch 53/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1083 - acc: 0.3496 - val_loss: 0.1085 - val_acc: 0.3504\n",
      "Epoch 54/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1083 - acc: 0.3525 - val_loss: 0.1094 - val_acc: 0.3366\n",
      "Epoch 55/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1082 - acc: 0.3504 - val_loss: 0.1089 - val_acc: 0.3376\n",
      "Epoch 56/100\n",
      "5707/5707 [==============================] - 29s 5ms/step - loss: 0.1082 - acc: 0.3483 - val_loss: 0.1088 - val_acc: 0.3346\n",
      "Epoch 57/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1080 - acc: 0.3587 - val_loss: 0.1092 - val_acc: 0.3258\n",
      "Epoch 58/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1080 - acc: 0.3571 - val_loss: 0.1088 - val_acc: 0.3643\n",
      "Epoch 59/100\n",
      "5707/5707 [==============================] - 37s 6ms/step - loss: 0.1080 - acc: 0.3554 - val_loss: 0.1087 - val_acc: 0.3485\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1079 - acc: 0.3529 - val_loss: 0.1091 - val_acc: 0.3386\n",
      "Epoch 61/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1078 - acc: 0.3524 - val_loss: 0.1088 - val_acc: 0.3416\n",
      "Epoch 62/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1076 - acc: 0.3564 - val_loss: 0.1090 - val_acc: 0.3327\n",
      "Epoch 63/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1076 - acc: 0.3538 - val_loss: 0.1090 - val_acc: 0.3544\n",
      "Epoch 64/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1079 - acc: 0.3601 - val_loss: 0.1086 - val_acc: 0.3544\n",
      "Epoch 65/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1077 - acc: 0.3582 - val_loss: 0.1085 - val_acc: 0.3495\n",
      "Epoch 66/100\n",
      "5707/5707 [==============================] - 35s 6ms/step - loss: 0.1077 - acc: 0.3554 - val_loss: 0.1086 - val_acc: 0.3475\n",
      "Epoch 67/100\n",
      "5707/5707 [==============================] - 40s 7ms/step - loss: 0.1074 - acc: 0.3587 - val_loss: 0.1088 - val_acc: 0.3613\n",
      "Epoch 68/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1077 - acc: 0.3566 - val_loss: 0.1085 - val_acc: 0.3514\n",
      "Epoch 69/100\n",
      "5707/5707 [==============================] - 38s 7ms/step - loss: 0.1076 - acc: 0.3589 - val_loss: 0.1092 - val_acc: 0.3297\n",
      "Epoch 70/100\n",
      "5707/5707 [==============================] - 33s 6ms/step - loss: 0.1075 - acc: 0.3627 - val_loss: 0.1087 - val_acc: 0.3554\n",
      "Epoch 71/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1071 - acc: 0.3722 - val_loss: 0.1093 - val_acc: 0.3238\n",
      "Epoch 72/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1073 - acc: 0.3652 - val_loss: 0.1086 - val_acc: 0.3495\n",
      "Epoch 73/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1072 - acc: 0.3657 - val_loss: 0.1088 - val_acc: 0.3603\n",
      "Epoch 74/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1070 - acc: 0.3680 - val_loss: 0.1087 - val_acc: 0.3514\n",
      "Epoch 75/100\n",
      "5707/5707 [==============================] - 28s 5ms/step - loss: 0.1070 - acc: 0.3688 - val_loss: 0.1087 - val_acc: 0.3277\n",
      "Epoch 76/100\n",
      "5707/5707 [==============================] - 31s 5ms/step - loss: 0.1068 - acc: 0.3695 - val_loss: 0.1085 - val_acc: 0.3425\n",
      "Epoch 77/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1068 - acc: 0.3688 - val_loss: 0.1090 - val_acc: 0.3465\n",
      "Epoch 78/100\n",
      "5707/5707 [==============================] - 31s 5ms/step - loss: 0.1068 - acc: 0.3709 - val_loss: 0.1092 - val_acc: 0.3524\n",
      "Epoch 79/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1070 - acc: 0.3671 - val_loss: 0.1088 - val_acc: 0.3485\n",
      "Epoch 80/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1064 - acc: 0.3704 - val_loss: 0.1092 - val_acc: 0.3544\n",
      "Epoch 81/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1064 - acc: 0.3713 - val_loss: 0.1086 - val_acc: 0.3593\n",
      "Epoch 82/100\n",
      "5707/5707 [==============================] - 33s 6ms/step - loss: 0.1064 - acc: 0.3720 - val_loss: 0.1091 - val_acc: 0.3376\n",
      "Epoch 83/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1064 - acc: 0.3722 - val_loss: 0.1089 - val_acc: 0.3435\n",
      "Epoch 84/100\n",
      "5707/5707 [==============================] - 34s 6ms/step - loss: 0.1064 - acc: 0.3764 - val_loss: 0.1090 - val_acc: 0.3583\n",
      "Epoch 85/100\n",
      "5707/5707 [==============================] - 27s 5ms/step - loss: 0.1062 - acc: 0.3809 - val_loss: 0.1092 - val_acc: 0.3544\n",
      "Epoch 86/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1064 - acc: 0.3662 - val_loss: 0.1089 - val_acc: 0.3544\n",
      "Epoch 87/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1065 - acc: 0.3697 - val_loss: 0.1088 - val_acc: 0.3356\n",
      "Epoch 88/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1061 - acc: 0.3774 - val_loss: 0.1088 - val_acc: 0.3524\n",
      "Epoch 89/100\n",
      "5707/5707 [==============================] - 26s 5ms/step - loss: 0.1061 - acc: 0.3736 - val_loss: 0.1100 - val_acc: 0.3179\n",
      "Epoch 90/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1062 - acc: 0.3702 - val_loss: 0.1090 - val_acc: 0.3416\n",
      "Epoch 91/100\n",
      "5707/5707 [==============================] - 35s 6ms/step - loss: 0.1062 - acc: 0.3729 - val_loss: 0.1094 - val_acc: 0.3475\n",
      "Epoch 92/100\n",
      "5707/5707 [==============================] - 34s 6ms/step - loss: 0.1057 - acc: 0.3771 - val_loss: 0.1091 - val_acc: 0.3495\n",
      "Epoch 93/100\n",
      "5707/5707 [==============================] - 33s 6ms/step - loss: 0.1060 - acc: 0.3790 - val_loss: 0.1088 - val_acc: 0.3504\n",
      "Epoch 94/100\n",
      "5707/5707 [==============================] - 30s 5ms/step - loss: 0.1058 - acc: 0.3790 - val_loss: 0.1088 - val_acc: 0.3504\n",
      "Epoch 95/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1056 - acc: 0.3792 - val_loss: 0.1091 - val_acc: 0.3554\n",
      "Epoch 96/100\n",
      "5707/5707 [==============================] - 41s 7ms/step - loss: 0.1059 - acc: 0.3753 - val_loss: 0.1092 - val_acc: 0.3337\n",
      "Epoch 97/100\n",
      "5707/5707 [==============================] - 32s 6ms/step - loss: 0.1057 - acc: 0.3815 - val_loss: 0.1092 - val_acc: 0.3534\n",
      "Epoch 98/100\n",
      "5707/5707 [==============================] - 25s 4ms/step - loss: 0.1058 - acc: 0.3702 - val_loss: 0.1098 - val_acc: 0.3149\n",
      "Epoch 99/100\n",
      "3904/5707 [===================>..........] - ETA: 8s - loss: 0.1064 - acc: 0.3712"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=32, epochs=100, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"test loss:\", score[0])\n",
    "print(\"test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('full_model.h5') #saving\n",
    "#model = load_model('full_model.h5') #loading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa\n",
    "#import librosa.display\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.pyplot import specgram\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Importing Data for Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4059, 216)\n",
      "4059 train samples\n",
      "458 test samples\n"
     ]
    }
   ],
   "source": [
    "emotionsDf = pd.read_csv(\"9_27_2018_5_53_pm_emotions_and_speakers.csv\")\n",
    "from sklearn.utils import shuffle\n",
    "shuffledDf = shuffle(emotionsDf)\n",
    "\n",
    "divider = np.random.rand(len(shuffledDf)) < 0.9\n",
    "train = shuffledDf[divider]\n",
    "test = shuffledDf[~divider]\n",
    "\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabels = train.iloc[:, -1:]\n",
    "\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabels = test.iloc[:, -1:]\n",
    "\n",
    "x_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabels)\n",
    "x_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabels)\n",
    "\n",
    "#flattening the arrays\n",
    "y_train = np.hstack(y_train)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "#convert class vectors to binary class matrices.\n",
    "num_classes = 7\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train = np.expand_dims(x_train, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(256, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adadelta()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt9Architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 216, 256)          512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 55296)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 387079    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 387,591\n",
      "Trainable params: 387,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model.add(Dense(256, input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt9_1Architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 216, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 216, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 108, 64)           6208      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 108, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 54, 32)            2080      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 54, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 12103     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 20,519\n",
      "Trainable params: 20,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 216, 32)           64        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 216, 32)           0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 216, 32)           1056      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 216, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 48391     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 49,511\n",
      "Trainable params: 49,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "model.add(Dense(32, input_shape=(216, 1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt9_2Architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 216, 32)           192       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 216, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 216, 32)           5152      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 216, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               442496    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 448,743\n",
      "Trainable params: 448,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same',input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt9_3Architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 458 samples\n",
      "Epoch 1/100\n",
      "4059/4059 [==============================] - 143s 35ms/step - loss: 3.0621 - acc: 0.2799 - val_loss: 1.5725 - val_acc: 0.3144\n",
      "Epoch 2/100\n",
      "4059/4059 [==============================] - 131s 32ms/step - loss: 1.5922 - acc: 0.3353 - val_loss: 1.5658 - val_acc: 0.3188\n",
      "Epoch 3/100\n",
      "4059/4059 [==============================] - 347s 86ms/step - loss: 1.4677 - acc: 0.3772 - val_loss: 1.5652 - val_acc: 0.3865\n",
      "Epoch 8/100\n",
      "4059/4059 [==============================] - 99s 24ms/step - loss: 1.4461 - acc: 0.4031 - val_loss: 1.5795 - val_acc: 0.3865\n",
      "Epoch 9/100\n",
      "4059/4059 [==============================] - 98s 24ms/step - loss: 1.4108 - acc: 0.4228 - val_loss: 1.5139 - val_acc: 0.4410\n",
      "Epoch 10/100\n",
      "4059/4059 [==============================] - 97s 24ms/step - loss: 1.4082 - acc: 0.4240 - val_loss: 1.4821 - val_acc: 0.4520\n",
      "Epoch 11/100\n",
      "4059/4059 [==============================] - 97s 24ms/step - loss: 1.3465 - acc: 0.4558 - val_loss: 1.4962 - val_acc: 0.4454\n",
      "Epoch 12/100\n",
      "4059/4059 [==============================] - 96s 24ms/step - loss: 1.3175 - acc: 0.4780 - val_loss: 1.4937 - val_acc: 0.4803\n",
      "Epoch 13/100\n",
      "4059/4059 [==============================] - 92s 23ms/step - loss: 1.2739 - acc: 0.5065 - val_loss: 1.5167 - val_acc: 0.4847\n",
      "Epoch 14/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 1.2579 - acc: 0.5087 - val_loss: 1.5678 - val_acc: 0.4520\n",
      "Epoch 15/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 1.2293 - acc: 0.5285 - val_loss: 1.5468 - val_acc: 0.4738\n",
      "Epoch 16/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.2093 - acc: 0.5294 - val_loss: 1.5331 - val_acc: 0.5197\n",
      "Epoch 17/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.1948 - acc: 0.5410 - val_loss: 1.5045 - val_acc: 0.5087\n",
      "Epoch 18/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.1596 - acc: 0.5546 - val_loss: 1.5021 - val_acc: 0.4651\n",
      "Epoch 19/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 1.1293 - acc: 0.5627 - val_loss: 1.5789 - val_acc: 0.5306\n",
      "Epoch 20/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 1.1084 - acc: 0.5775 - val_loss: 1.5713 - val_acc: 0.5349\n",
      "Epoch 21/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0672 - acc: 0.5920 - val_loss: 1.6280 - val_acc: 0.5284\n",
      "Epoch 22/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0659 - acc: 0.5864 - val_loss: 1.6407 - val_acc: 0.5153\n",
      "Epoch 23/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0557 - acc: 0.5947 - val_loss: 1.5562 - val_acc: 0.5087\n",
      "Epoch 24/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0272 - acc: 0.6149 - val_loss: 1.6781 - val_acc: 0.5240\n",
      "Epoch 25/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0311 - acc: 0.6053 - val_loss: 1.5540 - val_acc: 0.5131\n",
      "Epoch 26/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 1.0085 - acc: 0.6157 - val_loss: 1.5907 - val_acc: 0.5197\n",
      "Epoch 27/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9949 - acc: 0.6231 - val_loss: 1.6313 - val_acc: 0.5240\n",
      "Epoch 28/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9973 - acc: 0.6194 - val_loss: 1.6168 - val_acc: 0.5087\n",
      "Epoch 29/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9760 - acc: 0.6275 - val_loss: 1.6996 - val_acc: 0.5306\n",
      "Epoch 30/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9803 - acc: 0.6248 - val_loss: 1.7031 - val_acc: 0.5240\n",
      "Epoch 31/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.9517 - acc: 0.6433 - val_loss: 1.7034 - val_acc: 0.5131\n",
      "Epoch 32/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.9538 - acc: 0.6455 - val_loss: 1.7814 - val_acc: 0.5328\n",
      "Epoch 33/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9332 - acc: 0.6450 - val_loss: 1.7635 - val_acc: 0.5371\n",
      "Epoch 34/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9261 - acc: 0.6482 - val_loss: 1.8099 - val_acc: 0.5153\n",
      "Epoch 35/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.9121 - acc: 0.6556 - val_loss: 1.7903 - val_acc: 0.5197\n",
      "Epoch 36/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.8972 - acc: 0.6578 - val_loss: 1.7912 - val_acc: 0.4978\n",
      "Epoch 37/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.9210 - acc: 0.6499 - val_loss: 1.8056 - val_acc: 0.5109\n",
      "Epoch 38/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.8817 - acc: 0.6625 - val_loss: 1.7716 - val_acc: 0.5087\n",
      "Epoch 39/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.8945 - acc: 0.6647 - val_loss: 1.7474 - val_acc: 0.5218\n",
      "Epoch 40/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.9039 - acc: 0.6699 - val_loss: 1.7691 - val_acc: 0.5087\n",
      "Epoch 41/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8761 - acc: 0.6635 - val_loss: 1.8005 - val_acc: 0.5131\n",
      "Epoch 42/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8723 - acc: 0.6709 - val_loss: 1.7876 - val_acc: 0.5284\n",
      "Epoch 43/100\n",
      "4059/4059 [==============================] - 83s 21ms/step - loss: 0.8547 - acc: 0.6797 - val_loss: 1.8522 - val_acc: 0.5240\n",
      "Epoch 44/100\n",
      "4059/4059 [==============================] - 82s 20ms/step - loss: 0.8771 - acc: 0.6649 - val_loss: 1.8314 - val_acc: 0.5066\n",
      "Epoch 45/100\n",
      "4059/4059 [==============================] - 83s 20ms/step - loss: 0.8577 - acc: 0.6778 - val_loss: 1.8251 - val_acc: 0.5306\n",
      "Epoch 46/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8344 - acc: 0.6746 - val_loss: 1.9128 - val_acc: 0.5284\n",
      "Epoch 47/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8372 - acc: 0.6834 - val_loss: 2.0010 - val_acc: 0.5284\n",
      "Epoch 48/100\n",
      "4059/4059 [==============================] - 83s 21ms/step - loss: 0.8362 - acc: 0.6824 - val_loss: 1.9698 - val_acc: 0.5262\n",
      "Epoch 49/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8253 - acc: 0.6918 - val_loss: 1.9396 - val_acc: 0.5109\n",
      "Epoch 50/100\n",
      "4059/4059 [==============================] - 84s 21ms/step - loss: 0.8369 - acc: 0.6849 - val_loss: 1.9264 - val_acc: 0.5022\n",
      "Epoch 51/100\n",
      "4059/4059 [==============================] - 85s 21ms/step - loss: 0.8175 - acc: 0.6960 - val_loss: 1.9278 - val_acc: 0.5349\n",
      "Epoch 52/100\n",
      "4059/4059 [==============================] - 85s 21ms/step - loss: 0.8201 - acc: 0.6943 - val_loss: 1.9719 - val_acc: 0.5459\n",
      "Epoch 53/100\n",
      "4059/4059 [==============================] - 88s 22ms/step - loss: 0.8031 - acc: 0.6975 - val_loss: 1.8961 - val_acc: 0.5240\n",
      "Epoch 54/100\n",
      "4059/4059 [==============================] - 98s 24ms/step - loss: 0.7816 - acc: 0.7007 - val_loss: 1.9520 - val_acc: 0.5218\n",
      "Epoch 55/100\n",
      "4059/4059 [==============================] - 62s 15ms/step - loss: 0.7966 - acc: 0.6994 - val_loss: 1.9540 - val_acc: 0.5240\n",
      "Epoch 56/100\n",
      "4059/4059 [==============================] - 36s 9ms/step - loss: 0.7920 - acc: 0.6992 - val_loss: 1.8974 - val_acc: 0.5066\n",
      "Epoch 57/100\n",
      "4059/4059 [==============================] - 30s 7ms/step - loss: 0.7789 - acc: 0.7019 - val_loss: 1.9749 - val_acc: 0.5218\n",
      "Epoch 58/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.7875 - acc: 0.7044 - val_loss: 1.9517 - val_acc: 0.5371\n",
      "Epoch 59/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.7831 - acc: 0.6984 - val_loss: 1.9056 - val_acc: 0.5153\n",
      "Epoch 60/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.7524 - acc: 0.7132 - val_loss: 1.9977 - val_acc: 0.5175\n",
      "Epoch 61/100\n",
      "4059/4059 [==============================] - 39s 10ms/step - loss: 0.7477 - acc: 0.7278 - val_loss: 2.0268 - val_acc: 0.5218\n",
      "Epoch 62/100\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.7530 - acc: 0.7204 - val_loss: 1.9872 - val_acc: 0.5153\n",
      "Epoch 63/100\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.7359 - acc: 0.7290 - val_loss: 2.0034 - val_acc: 0.5066\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 38s 9ms/step - loss: 0.7407 - acc: 0.7260 - val_loss: 1.9542 - val_acc: 0.5262\n",
      "Epoch 65/100\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.7219 - acc: 0.7305 - val_loss: 1.9362 - val_acc: 0.5240\n",
      "Epoch 66/100\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.7052 - acc: 0.7322 - val_loss: 2.0168 - val_acc: 0.5175\n",
      "Epoch 67/100\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.7120 - acc: 0.7278 - val_loss: 2.1151 - val_acc: 0.4847\n",
      "Epoch 68/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.7012 - acc: 0.7391 - val_loss: 2.0204 - val_acc: 0.4891\n",
      "Epoch 69/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.6998 - acc: 0.7361 - val_loss: 2.0408 - val_acc: 0.5218\n",
      "Epoch 70/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.7090 - acc: 0.7310 - val_loss: 2.0153 - val_acc: 0.5066\n",
      "Epoch 71/100\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.7066 - acc: 0.7438 - val_loss: 2.1117 - val_acc: 0.5284\n",
      "Epoch 72/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.6735 - acc: 0.7470 - val_loss: 2.0976 - val_acc: 0.5240\n",
      "Epoch 73/100\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.6707 - acc: 0.7494 - val_loss: 2.0773 - val_acc: 0.5197\n",
      "Epoch 74/100\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.6757 - acc: 0.7522 - val_loss: 2.0423 - val_acc: 0.5240\n",
      "Epoch 75/100\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.6538 - acc: 0.7591 - val_loss: 2.0900 - val_acc: 0.5349\n",
      "Epoch 76/100\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.6311 - acc: 0.7618 - val_loss: 2.1783 - val_acc: 0.5153\n",
      "Epoch 77/100\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.6577 - acc: 0.7519 - val_loss: 2.1423 - val_acc: 0.5153\n",
      "Epoch 78/100\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.6335 - acc: 0.7591 - val_loss: 2.1944 - val_acc: 0.5087\n",
      "Epoch 79/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.6427 - acc: 0.7581 - val_loss: 2.2257 - val_acc: 0.5328\n",
      "Epoch 80/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.6495 - acc: 0.7566 - val_loss: 2.1716 - val_acc: 0.5240\n",
      "Epoch 81/100\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.6208 - acc: 0.7696 - val_loss: 2.2151 - val_acc: 0.5197\n",
      "Epoch 82/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.6195 - acc: 0.7689 - val_loss: 2.2377 - val_acc: 0.5262\n",
      "Epoch 83/100\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.6203 - acc: 0.7689 - val_loss: 2.2581 - val_acc: 0.5371\n",
      "Epoch 84/100\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.6211 - acc: 0.7694 - val_loss: 2.1852 - val_acc: 0.5306\n",
      "Epoch 85/100\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.6218 - acc: 0.7682 - val_loss: 2.2184 - val_acc: 0.5175\n",
      "Epoch 86/100\n",
      "4059/4059 [==============================] - 722s 178ms/step - loss: 0.6050 - acc: 0.7778 - val_loss: 2.2332 - val_acc: 0.4913\n",
      "Epoch 87/100\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.6395 - acc: 0.7652 - val_loss: 2.1993 - val_acc: 0.5218\n",
      "Epoch 88/100\n",
      "4059/4059 [==============================] - 2610s 643ms/step - loss: 0.6196 - acc: 0.7694 - val_loss: 2.2444 - val_acc: 0.5437\n",
      "Epoch 89/100\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.5996 - acc: 0.7699 - val_loss: 2.2338 - val_acc: 0.4978\n",
      "Epoch 90/100\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.6147 - acc: 0.7711 - val_loss: 2.2612 - val_acc: 0.5306\n",
      "Epoch 91/100\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.5821 - acc: 0.7770 - val_loss: 2.3363 - val_acc: 0.5306\n",
      "Epoch 92/100\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.6167 - acc: 0.7694 - val_loss: 2.2756 - val_acc: 0.5087\n",
      "Epoch 93/100\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.5873 - acc: 0.7815 - val_loss: 2.3513 - val_acc: 0.5240\n",
      "Epoch 94/100\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.6053 - acc: 0.7778 - val_loss: 2.2586 - val_acc: 0.5284\n",
      "Epoch 95/100\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.5930 - acc: 0.7812 - val_loss: 2.2501 - val_acc: 0.5262\n",
      "Epoch 96/100\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.5813 - acc: 0.7832 - val_loss: 2.2724 - val_acc: 0.5131\n",
      "Epoch 97/100\n",
      "4059/4059 [==============================] - 349s 86ms/step - loss: 0.5851 - acc: 0.7672 - val_loss: 2.2763 - val_acc: 0.5218\n",
      "Epoch 98/100\n",
      "4059/4059 [==============================] - 36s 9ms/step - loss: 0.5938 - acc: 0.7802 - val_loss: 2.3500 - val_acc: 0.5262\n",
      "Epoch 99/100\n",
      "4059/4059 [==============================] - 2992s 737ms/step - loss: 0.5664 - acc: 0.7935 - val_loss: 2.2567 - val_acc: 0.5044\n",
      "Epoch 100/100\n",
      "4059/4059 [==============================] - 26s 7ms/step - loss: 0.5871 - acc: 0.7805 - val_loss: 2.2915 - val_acc: 0.5109\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensor_board = TensorBoard(log_dir='./Graph/run4', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "cnnhistory = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test), \n",
    "                callbacks=[tensor_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(cnnhistory.history['acc'])\n",
    "# plt.plot(cnnhistory.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.savefig(\"Attempt9Acc.png\")\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"Attempt9Loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#sigmoid\n",
    "plt.plot(cnnhistory.history['acc'])\n",
    "plt.plot(cnnhistory.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_rate = librosa.load(\"test_sample_d.wav\", res_type='kaiser_fast',duration=5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature0 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_a.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature1 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_s.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature2 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_sample_a_2.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature3 = mfccs\n",
    "\n",
    "X, sample_rate = librosa.load(\"test_surprise.wav\", res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "feature4 = mfccs\n",
    "\n",
    "\n",
    "feature0 = np.pad(feature0, (0, 216-feature0.shape[0]), 'mean')\n",
    "feature0 = feature0.reshape(1, 216, 1)\n",
    "\n",
    "feature1 = np.pad(feature1, (0, 216-feature1.shape[0]), 'mean')\n",
    "feature1 = feature1.reshape(1, 216, 1)\n",
    "\n",
    "feature2 = np.pad(feature2, (0, 216-feature2.shape[0]), 'mean')\n",
    "feature2 = feature2.reshape(1, 216, 1)\n",
    "\n",
    "feature3 = np.pad(feature3, (0, 216-feature3.shape[0]), 'mean')\n",
    "feature3 = feature3.reshape(1, 216, 1)\n",
    "\n",
    "feature4 = np.pad(feature4, (0, 216-feature4.shape[0]), 'mean')\n",
    "feature4 = feature4.reshape(1,216,1)\n",
    "\n",
    "# feats = [feature0, feature1]\n",
    "# 0 angry\n",
    "# 1 fear\n",
    "# 2 disgust\n",
    "# 3 happy\n",
    "# 4 sad\n",
    "# 5 neutral\n",
    "# 6 surprise\n",
    "\n",
    "\n",
    "prediction0 = model.predict_classes(feature0)\n",
    "prediction1 = model.predict_classes(feature1)\n",
    "prediction2 = model.predict_classes(feature2)\n",
    "prediction3 = model.predict_classes(feature3)\n",
    "prediction4 = model.predict_classes(feature4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".    [5]\n"
     ]
    }
   ],
   "source": [
    "print(\".   \", prediction0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

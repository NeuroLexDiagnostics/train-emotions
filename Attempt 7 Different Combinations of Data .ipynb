{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucaslyon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import librosa\n",
    "#import librosa.display\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib.pyplot import specgram\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Model2.h trained with 9_24_2018_1_43_pm_emotions_and_speakers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-36.119404</td>\n",
       "      <td>-35.437660</td>\n",
       "      <td>-35.342020</td>\n",
       "      <td>-32.386917</td>\n",
       "      <td>-30.536057</td>\n",
       "      <td>-30.214967</td>\n",
       "      <td>-27.654420</td>\n",
       "      <td>-23.548437</td>\n",
       "      <td>-24.878867</td>\n",
       "      <td>-31.028803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-35.325222</td>\n",
       "      <td>-37.073929</td>\n",
       "      <td>-38.788249</td>\n",
       "      <td>-35.580948</td>\n",
       "      <td>-33.228233</td>\n",
       "      <td>-34.641827</td>\n",
       "      <td>-33.711400</td>\n",
       "      <td>-29.087174</td>\n",
       "      <td>-25.206979</td>\n",
       "      <td>-25.905561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-35.645841</td>\n",
       "      <td>-37.032590</td>\n",
       "      <td>-38.005329</td>\n",
       "      <td>-34.593591</td>\n",
       "      <td>-30.906771</td>\n",
       "      <td>-30.536100</td>\n",
       "      <td>-29.615748</td>\n",
       "      <td>-27.486853</td>\n",
       "      <td>-26.178317</td>\n",
       "      <td>-28.742591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-35.628404</td>\n",
       "      <td>-35.779406</td>\n",
       "      <td>-35.889227</td>\n",
       "      <td>-33.469289</td>\n",
       "      <td>-30.499761</td>\n",
       "      <td>-28.906997</td>\n",
       "      <td>-26.013903</td>\n",
       "      <td>-23.390519</td>\n",
       "      <td>-23.129202</td>\n",
       "      <td>-26.473794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-38.410901</td>\n",
       "      <td>-37.830037</td>\n",
       "      <td>-35.665460</td>\n",
       "      <td>-33.211890</td>\n",
       "      <td>-31.612501</td>\n",
       "      <td>-28.813875</td>\n",
       "      <td>-22.877424</td>\n",
       "      <td>-21.912161</td>\n",
       "      <td>-25.647788</td>\n",
       "      <td>-27.259637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-33.738992</td>\n",
       "      <td>-36.090071</td>\n",
       "      <td>-38.203464</td>\n",
       "      <td>-34.524252</td>\n",
       "      <td>-31.192582</td>\n",
       "      <td>-31.457412</td>\n",
       "      <td>-32.630453</td>\n",
       "      <td>-31.484759</td>\n",
       "      <td>-29.343753</td>\n",
       "      <td>-26.266214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-37.853301</td>\n",
       "      <td>-34.095181</td>\n",
       "      <td>-30.555515</td>\n",
       "      <td>-28.967747</td>\n",
       "      <td>-28.104705</td>\n",
       "      <td>-27.483383</td>\n",
       "      <td>-25.176573</td>\n",
       "      <td>-25.526112</td>\n",
       "      <td>-28.770776</td>\n",
       "      <td>-30.376255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-35.876410</td>\n",
       "      <td>-36.738398</td>\n",
       "      <td>-35.779723</td>\n",
       "      <td>-32.491711</td>\n",
       "      <td>-31.789602</td>\n",
       "      <td>-33.042159</td>\n",
       "      <td>-25.811531</td>\n",
       "      <td>-22.226235</td>\n",
       "      <td>-25.146416</td>\n",
       "      <td>-30.370430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-39.001275</td>\n",
       "      <td>-39.097649</td>\n",
       "      <td>-35.823715</td>\n",
       "      <td>-31.933046</td>\n",
       "      <td>-28.300981</td>\n",
       "      <td>-26.838530</td>\n",
       "      <td>-25.930366</td>\n",
       "      <td>-27.157401</td>\n",
       "      <td>-23.777345</td>\n",
       "      <td>-21.083639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-40.800523</td>\n",
       "      <td>-39.377241</td>\n",
       "      <td>-38.215374</td>\n",
       "      <td>-35.058872</td>\n",
       "      <td>-33.209757</td>\n",
       "      <td>-32.345631</td>\n",
       "      <td>-30.777799</td>\n",
       "      <td>-28.998303</td>\n",
       "      <td>-28.157424</td>\n",
       "      <td>-27.713642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-35.573899</td>\n",
       "      <td>-35.771782</td>\n",
       "      <td>-33.810374</td>\n",
       "      <td>-31.124098</td>\n",
       "      <td>-30.169570</td>\n",
       "      <td>-30.766161</td>\n",
       "      <td>-29.700028</td>\n",
       "      <td>-26.230353</td>\n",
       "      <td>-24.939779</td>\n",
       "      <td>-25.183041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-36.078710</td>\n",
       "      <td>-37.304982</td>\n",
       "      <td>-37.722394</td>\n",
       "      <td>-34.681964</td>\n",
       "      <td>-31.207535</td>\n",
       "      <td>-29.619398</td>\n",
       "      <td>-29.115092</td>\n",
       "      <td>-31.103251</td>\n",
       "      <td>-26.692056</td>\n",
       "      <td>-24.056260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-35.432207</td>\n",
       "      <td>-34.936541</td>\n",
       "      <td>-34.218046</td>\n",
       "      <td>-32.654370</td>\n",
       "      <td>-31.571644</td>\n",
       "      <td>-29.174091</td>\n",
       "      <td>-26.304610</td>\n",
       "      <td>-26.613197</td>\n",
       "      <td>-30.580761</td>\n",
       "      <td>-32.976133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-35.718528</td>\n",
       "      <td>-36.151848</td>\n",
       "      <td>-35.332581</td>\n",
       "      <td>-32.146923</td>\n",
       "      <td>-30.431539</td>\n",
       "      <td>-25.904434</td>\n",
       "      <td>-24.103111</td>\n",
       "      <td>-26.903841</td>\n",
       "      <td>-27.798363</td>\n",
       "      <td>-30.311584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-35.668200</td>\n",
       "      <td>-36.715466</td>\n",
       "      <td>-37.231288</td>\n",
       "      <td>-34.452714</td>\n",
       "      <td>-32.469415</td>\n",
       "      <td>-31.063660</td>\n",
       "      <td>-29.843325</td>\n",
       "      <td>-29.497031</td>\n",
       "      <td>-26.702806</td>\n",
       "      <td>-23.383901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-36.764450</td>\n",
       "      <td>-35.406902</td>\n",
       "      <td>-34.565832</td>\n",
       "      <td>-33.015237</td>\n",
       "      <td>-31.263844</td>\n",
       "      <td>-27.401119</td>\n",
       "      <td>-23.517074</td>\n",
       "      <td>-24.272194</td>\n",
       "      <td>-28.596031</td>\n",
       "      <td>-29.237004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-38.581911</td>\n",
       "      <td>-39.954730</td>\n",
       "      <td>-38.041092</td>\n",
       "      <td>-36.507155</td>\n",
       "      <td>-34.037433</td>\n",
       "      <td>-30.003008</td>\n",
       "      <td>-28.103799</td>\n",
       "      <td>-28.048415</td>\n",
       "      <td>-26.726359</td>\n",
       "      <td>-24.126061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-36.054563</td>\n",
       "      <td>-38.318868</td>\n",
       "      <td>-39.849914</td>\n",
       "      <td>-37.529668</td>\n",
       "      <td>-33.612378</td>\n",
       "      <td>-31.503376</td>\n",
       "      <td>-31.744953</td>\n",
       "      <td>-32.078588</td>\n",
       "      <td>-28.473025</td>\n",
       "      <td>-22.898768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-36.548448</td>\n",
       "      <td>-34.630685</td>\n",
       "      <td>-32.521696</td>\n",
       "      <td>-32.992766</td>\n",
       "      <td>-29.446946</td>\n",
       "      <td>-24.230241</td>\n",
       "      <td>-23.243730</td>\n",
       "      <td>-23.403430</td>\n",
       "      <td>-24.746574</td>\n",
       "      <td>-27.448420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-35.946511</td>\n",
       "      <td>-35.137376</td>\n",
       "      <td>-33.556172</td>\n",
       "      <td>-32.187801</td>\n",
       "      <td>-31.143517</td>\n",
       "      <td>-29.799816</td>\n",
       "      <td>-27.444782</td>\n",
       "      <td>-26.563062</td>\n",
       "      <td>-28.344539</td>\n",
       "      <td>-30.682944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-38.158599</td>\n",
       "      <td>-38.107604</td>\n",
       "      <td>-36.657617</td>\n",
       "      <td>-33.642754</td>\n",
       "      <td>-30.228046</td>\n",
       "      <td>-28.443555</td>\n",
       "      <td>-28.016156</td>\n",
       "      <td>-26.810886</td>\n",
       "      <td>-23.732390</td>\n",
       "      <td>-20.060123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-36.333431</td>\n",
       "      <td>-35.724070</td>\n",
       "      <td>-34.262156</td>\n",
       "      <td>-32.626941</td>\n",
       "      <td>-31.169005</td>\n",
       "      <td>-28.806248</td>\n",
       "      <td>-26.033109</td>\n",
       "      <td>-25.890417</td>\n",
       "      <td>-29.243048</td>\n",
       "      <td>-29.504144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-36.045729</td>\n",
       "      <td>-38.379748</td>\n",
       "      <td>-41.925201</td>\n",
       "      <td>-38.116401</td>\n",
       "      <td>-35.803415</td>\n",
       "      <td>-32.147884</td>\n",
       "      <td>-31.713522</td>\n",
       "      <td>-31.112697</td>\n",
       "      <td>-29.784670</td>\n",
       "      <td>-27.872223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-36.781486</td>\n",
       "      <td>-37.640524</td>\n",
       "      <td>-37.303671</td>\n",
       "      <td>-35.082198</td>\n",
       "      <td>-31.406318</td>\n",
       "      <td>-30.495223</td>\n",
       "      <td>-29.637484</td>\n",
       "      <td>-27.181203</td>\n",
       "      <td>-27.820088</td>\n",
       "      <td>-31.960785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-41.751151</td>\n",
       "      <td>-40.289918</td>\n",
       "      <td>-38.125055</td>\n",
       "      <td>-37.952656</td>\n",
       "      <td>-36.385426</td>\n",
       "      <td>-34.382371</td>\n",
       "      <td>-33.753916</td>\n",
       "      <td>-30.158459</td>\n",
       "      <td>-26.667678</td>\n",
       "      <td>-27.586738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-35.734185</td>\n",
       "      <td>-35.450194</td>\n",
       "      <td>-33.975423</td>\n",
       "      <td>-32.188361</td>\n",
       "      <td>-32.217567</td>\n",
       "      <td>-32.702394</td>\n",
       "      <td>-29.281467</td>\n",
       "      <td>-25.486285</td>\n",
       "      <td>-26.955471</td>\n",
       "      <td>-30.582568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-35.917064</td>\n",
       "      <td>-34.968717</td>\n",
       "      <td>-34.534126</td>\n",
       "      <td>-33.247863</td>\n",
       "      <td>-30.597796</td>\n",
       "      <td>-28.666796</td>\n",
       "      <td>-27.754079</td>\n",
       "      <td>-25.246368</td>\n",
       "      <td>-25.420599</td>\n",
       "      <td>-29.144560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-39.689176</td>\n",
       "      <td>-39.829193</td>\n",
       "      <td>-39.700398</td>\n",
       "      <td>-39.738326</td>\n",
       "      <td>-39.405478</td>\n",
       "      <td>-37.377958</td>\n",
       "      <td>-34.475837</td>\n",
       "      <td>-30.805294</td>\n",
       "      <td>-29.276661</td>\n",
       "      <td>-26.802264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-37.039040</td>\n",
       "      <td>-37.636495</td>\n",
       "      <td>-36.010081</td>\n",
       "      <td>-33.654141</td>\n",
       "      <td>-32.229626</td>\n",
       "      <td>-30.045458</td>\n",
       "      <td>-24.788177</td>\n",
       "      <td>-21.252485</td>\n",
       "      <td>-22.564457</td>\n",
       "      <td>-26.753336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-34.055871</td>\n",
       "      <td>-33.168339</td>\n",
       "      <td>-31.973168</td>\n",
       "      <td>-30.613366</td>\n",
       "      <td>-28.429288</td>\n",
       "      <td>-27.566452</td>\n",
       "      <td>-28.610422</td>\n",
       "      <td>-31.311367</td>\n",
       "      <td>-30.791007</td>\n",
       "      <td>-30.147918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>-67.128017</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.192277</td>\n",
       "      <td>-53.082673</td>\n",
       "      <td>-54.695262</td>\n",
       "      <td>-52.384729</td>\n",
       "      <td>-53.175544</td>\n",
       "      <td>-54.981104</td>\n",
       "      <td>-54.078131</td>\n",
       "      <td>-54.207101</td>\n",
       "      <td>-56.474811</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>-59.699105</td>\n",
       "      <td>-59.587370</td>\n",
       "      <td>-59.571284</td>\n",
       "      <td>-59.328462</td>\n",
       "      <td>-59.369630</td>\n",
       "      <td>-59.321506</td>\n",
       "      <td>-59.319399</td>\n",
       "      <td>-59.590825</td>\n",
       "      <td>-59.591379</td>\n",
       "      <td>-59.675603</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.058435</td>\n",
       "      <td>-34.644343</td>\n",
       "      <td>-34.442063</td>\n",
       "      <td>-36.707547</td>\n",
       "      <td>-41.146307</td>\n",
       "      <td>-43.172390</td>\n",
       "      <td>-42.835244</td>\n",
       "      <td>-46.150078</td>\n",
       "      <td>-45.851973</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>-54.677157</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.009244</td>\n",
       "      <td>-40.035804</td>\n",
       "      <td>-39.657108</td>\n",
       "      <td>-40.550019</td>\n",
       "      <td>-43.559956</td>\n",
       "      <td>-45.444457</td>\n",
       "      <td>-46.496016</td>\n",
       "      <td>-46.470699</td>\n",
       "      <td>-47.322224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.849780</td>\n",
       "      <td>-59.863135</td>\n",
       "      <td>-60.327359</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.885912</td>\n",
       "      <td>-59.354939</td>\n",
       "      <td>-59.807379</td>\n",
       "      <td>-59.775160</td>\n",
       "      <td>-58.808937</td>\n",
       "      <td>-57.853232</td>\n",
       "      <td>-58.398109</td>\n",
       "      <td>-59.114060</td>\n",
       "      <td>-58.564454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>-54.897441</td>\n",
       "      <td>-55.061032</td>\n",
       "      <td>-54.983695</td>\n",
       "      <td>-55.102022</td>\n",
       "      <td>-55.289954</td>\n",
       "      <td>-55.346702</td>\n",
       "      <td>-55.382404</td>\n",
       "      <td>-55.439658</td>\n",
       "      <td>-55.337597</td>\n",
       "      <td>-54.012888</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.287239</td>\n",
       "      <td>-39.428942</td>\n",
       "      <td>-41.273553</td>\n",
       "      <td>-40.047037</td>\n",
       "      <td>-40.112812</td>\n",
       "      <td>-43.898186</td>\n",
       "      <td>-46.512260</td>\n",
       "      <td>-45.556203</td>\n",
       "      <td>-43.528693</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>-44.552925</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.175252</td>\n",
       "      <td>-37.902636</td>\n",
       "      <td>-40.407236</td>\n",
       "      <td>-40.815793</td>\n",
       "      <td>-41.241603</td>\n",
       "      <td>-41.736607</td>\n",
       "      <td>-43.396698</td>\n",
       "      <td>-42.237670</td>\n",
       "      <td>-41.635098</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>-48.668418</td>\n",
       "      <td>-45.720402</td>\n",
       "      <td>-46.046837</td>\n",
       "      <td>-46.525805</td>\n",
       "      <td>-47.946480</td>\n",
       "      <td>-44.790188</td>\n",
       "      <td>-43.489744</td>\n",
       "      <td>-46.490625</td>\n",
       "      <td>-50.799665</td>\n",
       "      <td>-50.240377</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.281609</td>\n",
       "      <td>-48.504020</td>\n",
       "      <td>-50.357992</td>\n",
       "      <td>-44.687362</td>\n",
       "      <td>-43.194414</td>\n",
       "      <td>-46.666642</td>\n",
       "      <td>-50.128142</td>\n",
       "      <td>-50.941980</td>\n",
       "      <td>-50.317816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.565868</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-56.719102</td>\n",
       "      <td>-56.908147</td>\n",
       "      <td>-56.898329</td>\n",
       "      <td>-57.050586</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>-57.262080</td>\n",
       "      <td>-57.332370</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>-56.079682</td>\n",
       "      <td>-56.079682</td>\n",
       "      <td>-56.079682</td>\n",
       "      <td>-56.079682</td>\n",
       "      <td>-56.079682</td>\n",
       "      <td>-56.109858</td>\n",
       "      <td>-56.402303</td>\n",
       "      <td>-55.341964</td>\n",
       "      <td>-55.211303</td>\n",
       "      <td>-56.189707</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.765619</td>\n",
       "      <td>-45.138881</td>\n",
       "      <td>-45.866570</td>\n",
       "      <td>-44.450824</td>\n",
       "      <td>-45.075534</td>\n",
       "      <td>-47.864657</td>\n",
       "      <td>-49.669654</td>\n",
       "      <td>-52.591634</td>\n",
       "      <td>-54.877643</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>-64.678723</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.665689</td>\n",
       "      <td>-61.047234</td>\n",
       "      <td>-59.299474</td>\n",
       "      <td>-60.432158</td>\n",
       "      <td>-62.515880</td>\n",
       "      <td>-64.088474</td>\n",
       "      <td>-64.658195</td>\n",
       "      <td>-64.604102</td>\n",
       "      <td>-64.560031</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>-65.562365</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.889744</td>\n",
       "      <td>-61.001034</td>\n",
       "      <td>-61.759804</td>\n",
       "      <td>-62.241800</td>\n",
       "      <td>-62.069901</td>\n",
       "      <td>-61.062766</td>\n",
       "      <td>-58.563208</td>\n",
       "      <td>-60.640275</td>\n",
       "      <td>-63.574741</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>-66.807157</td>\n",
       "      <td>-67.642669</td>\n",
       "      <td>-67.920088</td>\n",
       "      <td>-68.177969</td>\n",
       "      <td>-67.961404</td>\n",
       "      <td>-67.855784</td>\n",
       "      <td>-68.056359</td>\n",
       "      <td>-67.975604</td>\n",
       "      <td>-67.535529</td>\n",
       "      <td>-67.833166</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.913939</td>\n",
       "      <td>-57.802619</td>\n",
       "      <td>-59.957985</td>\n",
       "      <td>-62.548852</td>\n",
       "      <td>-66.173967</td>\n",
       "      <td>-64.493243</td>\n",
       "      <td>-62.488814</td>\n",
       "      <td>-63.460311</td>\n",
       "      <td>-64.412657</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>-65.356763</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.523709</td>\n",
       "      <td>-56.629023</td>\n",
       "      <td>-57.543099</td>\n",
       "      <td>-58.982573</td>\n",
       "      <td>-57.795045</td>\n",
       "      <td>-57.904399</td>\n",
       "      <td>-58.457920</td>\n",
       "      <td>-60.506432</td>\n",
       "      <td>-59.845687</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.666244</td>\n",
       "      <td>-45.259188</td>\n",
       "      <td>-45.147653</td>\n",
       "      <td>-45.233620</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>-45.194876</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.989357</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>-52.044049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-60.665468</td>\n",
       "      <td>-60.689583</td>\n",
       "      <td>-59.735563</td>\n",
       "      <td>-60.501480</td>\n",
       "      <td>-60.420515</td>\n",
       "      <td>-59.816253</td>\n",
       "      <td>-60.189272</td>\n",
       "      <td>-60.110914</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.916401</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>-58.988811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.943359</td>\n",
       "      <td>-57.077028</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-56.940813</td>\n",
       "      <td>-57.228633</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.686466</td>\n",
       "      <td>-44.226132</td>\n",
       "      <td>-44.101891</td>\n",
       "      <td>-43.651345</td>\n",
       "      <td>-45.493498</td>\n",
       "      <td>-47.759692</td>\n",
       "      <td>-50.536515</td>\n",
       "      <td>-51.336391</td>\n",
       "      <td>-50.690862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.957350</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.942344</td>\n",
       "      <td>-63.933362</td>\n",
       "      <td>-63.799121</td>\n",
       "      <td>-63.616188</td>\n",
       "      <td>-63.476149</td>\n",
       "      <td>-63.391090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>-71.407071</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.321623</td>\n",
       "      <td>-66.922372</td>\n",
       "      <td>-70.591707</td>\n",
       "      <td>-69.530834</td>\n",
       "      <td>-66.970003</td>\n",
       "      <td>-66.873352</td>\n",
       "      <td>-68.084319</td>\n",
       "      <td>-70.437988</td>\n",
       "      <td>-70.868711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-64.968548</td>\n",
       "      <td>-67.252646</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.678076</td>\n",
       "      <td>-64.360786</td>\n",
       "      <td>-64.642809</td>\n",
       "      <td>-62.274782</td>\n",
       "      <td>-62.417866</td>\n",
       "      <td>-63.560128</td>\n",
       "      <td>-63.105106</td>\n",
       "      <td>-63.359077</td>\n",
       "      <td>-63.284678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>-55.767393</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.569010</td>\n",
       "      <td>-36.725955</td>\n",
       "      <td>-38.104478</td>\n",
       "      <td>-38.821533</td>\n",
       "      <td>-38.295397</td>\n",
       "      <td>-36.559404</td>\n",
       "      <td>-36.244597</td>\n",
       "      <td>-35.140083</td>\n",
       "      <td>-32.330563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>-74.012896</td>\n",
       "      <td>-73.948519</td>\n",
       "      <td>-73.379063</td>\n",
       "      <td>-71.428494</td>\n",
       "      <td>-72.432060</td>\n",
       "      <td>-74.236830</td>\n",
       "      <td>-73.548430</td>\n",
       "      <td>-71.061247</td>\n",
       "      <td>-71.375159</td>\n",
       "      <td>-73.176079</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.070428</td>\n",
       "      <td>-48.173410</td>\n",
       "      <td>-49.330655</td>\n",
       "      <td>-51.711174</td>\n",
       "      <td>-52.365458</td>\n",
       "      <td>-54.464719</td>\n",
       "      <td>-56.410372</td>\n",
       "      <td>-56.113212</td>\n",
       "      <td>-54.474242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>-64.793803</td>\n",
       "      <td>-64.793803</td>\n",
       "      <td>-64.793803</td>\n",
       "      <td>-65.559996</td>\n",
       "      <td>-65.851749</td>\n",
       "      <td>-65.446570</td>\n",
       "      <td>-66.626091</td>\n",
       "      <td>-66.020631</td>\n",
       "      <td>-66.533440</td>\n",
       "      <td>-64.211415</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.016013</td>\n",
       "      <td>-61.026796</td>\n",
       "      <td>-61.306973</td>\n",
       "      <td>-61.006645</td>\n",
       "      <td>-60.669009</td>\n",
       "      <td>-62.031732</td>\n",
       "      <td>-64.399412</td>\n",
       "      <td>-64.815625</td>\n",
       "      <td>-64.799419</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.247894</td>\n",
       "      <td>-63.931406</td>\n",
       "      <td>-64.395909</td>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.448001</td>\n",
       "      <td>-64.244446</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.155677</td>\n",
       "      <td>-46.213197</td>\n",
       "      <td>-48.122823</td>\n",
       "      <td>-45.521263</td>\n",
       "      <td>-45.774197</td>\n",
       "      <td>-49.803602</td>\n",
       "      <td>-51.963733</td>\n",
       "      <td>-52.965988</td>\n",
       "      <td>-52.242500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-54.024092</td>\n",
       "      <td>-54.198564</td>\n",
       "      <td>-53.286076</td>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-52.388832</td>\n",
       "      <td>-52.399767</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.524053</td>\n",
       "      <td>-46.362766</td>\n",
       "      <td>-46.383047</td>\n",
       "      <td>-47.492377</td>\n",
       "      <td>-51.348980</td>\n",
       "      <td>-51.252681</td>\n",
       "      <td>-50.509345</td>\n",
       "      <td>-49.606151</td>\n",
       "      <td>-47.599135</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>-69.567537</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.286208</td>\n",
       "      <td>-43.042348</td>\n",
       "      <td>-42.400162</td>\n",
       "      <td>-42.409806</td>\n",
       "      <td>-41.685644</td>\n",
       "      <td>-41.405289</td>\n",
       "      <td>-42.035714</td>\n",
       "      <td>-40.774790</td>\n",
       "      <td>-38.137740</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>-55.897192</td>\n",
       "      <td>-55.845639</td>\n",
       "      <td>-55.693414</td>\n",
       "      <td>-55.669094</td>\n",
       "      <td>-55.983359</td>\n",
       "      <td>-56.143512</td>\n",
       "      <td>-56.128047</td>\n",
       "      <td>-55.966648</td>\n",
       "      <td>-55.947412</td>\n",
       "      <td>-55.989351</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.450151</td>\n",
       "      <td>-26.664525</td>\n",
       "      <td>-28.591213</td>\n",
       "      <td>-29.936010</td>\n",
       "      <td>-29.608872</td>\n",
       "      <td>-31.826348</td>\n",
       "      <td>-36.193416</td>\n",
       "      <td>-37.252570</td>\n",
       "      <td>-37.633020</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>-53.054884</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.203255</td>\n",
       "      <td>-49.621696</td>\n",
       "      <td>-52.275230</td>\n",
       "      <td>-51.447833</td>\n",
       "      <td>-51.883657</td>\n",
       "      <td>-52.533490</td>\n",
       "      <td>-50.991376</td>\n",
       "      <td>-48.410666</td>\n",
       "      <td>-47.317401</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>-64.206723</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.251821</td>\n",
       "      <td>-58.833817</td>\n",
       "      <td>-57.978339</td>\n",
       "      <td>-61.298153</td>\n",
       "      <td>-58.773552</td>\n",
       "      <td>-60.140413</td>\n",
       "      <td>-63.886547</td>\n",
       "      <td>-63.014960</td>\n",
       "      <td>-63.745278</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>-55.255136</td>\n",
       "      <td>-55.255136</td>\n",
       "      <td>-55.186653</td>\n",
       "      <td>-55.345294</td>\n",
       "      <td>-55.053389</td>\n",
       "      <td>-53.088172</td>\n",
       "      <td>-52.199923</td>\n",
       "      <td>-52.218305</td>\n",
       "      <td>-52.633871</td>\n",
       "      <td>-51.629967</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.145131</td>\n",
       "      <td>-48.712166</td>\n",
       "      <td>-47.603032</td>\n",
       "      <td>-45.205415</td>\n",
       "      <td>-44.438685</td>\n",
       "      <td>-48.720497</td>\n",
       "      <td>-50.850345</td>\n",
       "      <td>-50.327162</td>\n",
       "      <td>-48.915758</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4517 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5  \\\n",
       "0    -36.119404 -35.437660 -35.342020 -32.386917 -30.536057 -30.214967   \n",
       "1    -35.325222 -37.073929 -38.788249 -35.580948 -33.228233 -34.641827   \n",
       "2    -35.645841 -37.032590 -38.005329 -34.593591 -30.906771 -30.536100   \n",
       "3    -35.628404 -35.779406 -35.889227 -33.469289 -30.499761 -28.906997   \n",
       "4    -38.410901 -37.830037 -35.665460 -33.211890 -31.612501 -28.813875   \n",
       "5    -33.738992 -36.090071 -38.203464 -34.524252 -31.192582 -31.457412   \n",
       "6    -37.853301 -34.095181 -30.555515 -28.967747 -28.104705 -27.483383   \n",
       "7    -35.876410 -36.738398 -35.779723 -32.491711 -31.789602 -33.042159   \n",
       "8    -39.001275 -39.097649 -35.823715 -31.933046 -28.300981 -26.838530   \n",
       "9    -40.800523 -39.377241 -38.215374 -35.058872 -33.209757 -32.345631   \n",
       "10   -35.573899 -35.771782 -33.810374 -31.124098 -30.169570 -30.766161   \n",
       "11   -36.078710 -37.304982 -37.722394 -34.681964 -31.207535 -29.619398   \n",
       "12   -35.432207 -34.936541 -34.218046 -32.654370 -31.571644 -29.174091   \n",
       "13   -35.718528 -36.151848 -35.332581 -32.146923 -30.431539 -25.904434   \n",
       "14   -35.668200 -36.715466 -37.231288 -34.452714 -32.469415 -31.063660   \n",
       "15   -36.764450 -35.406902 -34.565832 -33.015237 -31.263844 -27.401119   \n",
       "16   -38.581911 -39.954730 -38.041092 -36.507155 -34.037433 -30.003008   \n",
       "17   -36.054563 -38.318868 -39.849914 -37.529668 -33.612378 -31.503376   \n",
       "18   -36.548448 -34.630685 -32.521696 -32.992766 -29.446946 -24.230241   \n",
       "19   -35.946511 -35.137376 -33.556172 -32.187801 -31.143517 -29.799816   \n",
       "20   -38.158599 -38.107604 -36.657617 -33.642754 -30.228046 -28.443555   \n",
       "21   -36.333431 -35.724070 -34.262156 -32.626941 -31.169005 -28.806248   \n",
       "22   -36.045729 -38.379748 -41.925201 -38.116401 -35.803415 -32.147884   \n",
       "23   -36.781486 -37.640524 -37.303671 -35.082198 -31.406318 -30.495223   \n",
       "24   -41.751151 -40.289918 -38.125055 -37.952656 -36.385426 -34.382371   \n",
       "25   -35.734185 -35.450194 -33.975423 -32.188361 -32.217567 -32.702394   \n",
       "26   -35.917064 -34.968717 -34.534126 -33.247863 -30.597796 -28.666796   \n",
       "27   -39.689176 -39.829193 -39.700398 -39.738326 -39.405478 -37.377958   \n",
       "28   -37.039040 -37.636495 -36.010081 -33.654141 -32.229626 -30.045458   \n",
       "29   -34.055871 -33.168339 -31.973168 -30.613366 -28.429288 -27.566452   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4487 -67.128017 -67.128017 -67.128017 -67.128017 -67.128017 -67.128017   \n",
       "4488 -59.699105 -59.587370 -59.571284 -59.328462 -59.369630 -59.321506   \n",
       "4489 -54.677157 -54.677157 -54.677157 -54.677157 -54.677157 -54.677157   \n",
       "4490 -59.849780 -59.849780 -59.849780 -59.849780 -59.849780 -59.849780   \n",
       "4491 -54.897441 -55.061032 -54.983695 -55.102022 -55.289954 -55.346702   \n",
       "4492 -44.552925 -44.552925 -44.552925 -44.552925 -44.552925 -44.552925   \n",
       "4493 -48.668418 -45.720402 -46.046837 -46.525805 -47.946480 -44.790188   \n",
       "4494 -57.332370 -57.332370 -57.332370 -57.332370 -57.332370 -57.332370   \n",
       "4495 -56.079682 -56.079682 -56.079682 -56.079682 -56.079682 -56.109858   \n",
       "4496 -64.678723 -64.678723 -64.678723 -64.678723 -64.678723 -64.678723   \n",
       "4497 -65.562365 -65.562365 -65.562365 -65.562365 -65.562365 -65.562365   \n",
       "4498 -66.807157 -67.642669 -67.920088 -68.177969 -67.961404 -67.855784   \n",
       "4499 -65.356763 -65.356763 -65.356763 -65.356763 -65.356763 -65.356763   \n",
       "4500 -45.194876 -45.194876 -45.194876 -45.194876 -45.194876 -45.194876   \n",
       "4501 -52.044049 -52.044049 -52.044049 -52.044049 -52.044049 -52.044049   \n",
       "4502 -58.988811 -58.988811 -60.665468 -60.689583 -59.735563 -60.501480   \n",
       "4503 -56.940813 -56.940813 -56.940813 -56.940813 -56.940813 -56.943359   \n",
       "4504 -63.942344 -63.942344 -63.942344 -63.942344 -63.942344 -63.942344   \n",
       "4505 -71.407071 -71.407071 -71.407071 -71.407071 -71.407071 -71.407071   \n",
       "4506 -64.968548 -64.968548 -64.968548 -64.968548 -64.968548 -64.968548   \n",
       "4507 -55.767393 -55.767393 -55.767393 -55.767393 -55.767393 -55.767393   \n",
       "4508 -74.012896 -73.948519 -73.379063 -71.428494 -72.432060 -74.236830   \n",
       "4509 -64.793803 -64.793803 -64.793803 -65.559996 -65.851749 -65.446570   \n",
       "4510 -64.448001 -64.448001 -64.448001 -64.247894 -63.931406 -64.395909   \n",
       "4511 -52.388832 -52.388832 -52.388832 -52.388832 -54.024092 -54.198564   \n",
       "4512 -69.567537 -69.567537 -69.567537 -69.567537 -69.567537 -69.567537   \n",
       "4513 -55.897192 -55.845639 -55.693414 -55.669094 -55.983359 -56.143512   \n",
       "4514 -53.054884 -53.054884 -53.054884 -53.054884 -53.054884 -53.054884   \n",
       "4515 -64.206723 -64.206723 -64.206723 -64.206723 -64.206723 -64.206723   \n",
       "4516 -55.255136 -55.255136 -55.186653 -55.345294 -55.053389 -53.088172   \n",
       "\n",
       "              6          7          8          9 ...         207        208  \\\n",
       "0    -27.654420 -23.548437 -24.878867 -31.028803 ...    0.000000   0.000000   \n",
       "1    -33.711400 -29.087174 -25.206979 -25.905561 ...    0.000000   0.000000   \n",
       "2    -29.615748 -27.486853 -26.178317 -28.742591 ...    0.000000   0.000000   \n",
       "3    -26.013903 -23.390519 -23.129202 -26.473794 ...    0.000000   0.000000   \n",
       "4    -22.877424 -21.912161 -25.647788 -27.259637 ...    0.000000   0.000000   \n",
       "5    -32.630453 -31.484759 -29.343753 -26.266214 ...    0.000000   0.000000   \n",
       "6    -25.176573 -25.526112 -28.770776 -30.376255 ...    0.000000   0.000000   \n",
       "7    -25.811531 -22.226235 -25.146416 -30.370430 ...    0.000000   0.000000   \n",
       "8    -25.930366 -27.157401 -23.777345 -21.083639 ...    0.000000   0.000000   \n",
       "9    -30.777799 -28.998303 -28.157424 -27.713642 ...    0.000000   0.000000   \n",
       "10   -29.700028 -26.230353 -24.939779 -25.183041 ...    0.000000   0.000000   \n",
       "11   -29.115092 -31.103251 -26.692056 -24.056260 ...    0.000000   0.000000   \n",
       "12   -26.304610 -26.613197 -30.580761 -32.976133 ...    0.000000   0.000000   \n",
       "13   -24.103111 -26.903841 -27.798363 -30.311584 ...    0.000000   0.000000   \n",
       "14   -29.843325 -29.497031 -26.702806 -23.383901 ...    0.000000   0.000000   \n",
       "15   -23.517074 -24.272194 -28.596031 -29.237004 ...    0.000000   0.000000   \n",
       "16   -28.103799 -28.048415 -26.726359 -24.126061 ...    0.000000   0.000000   \n",
       "17   -31.744953 -32.078588 -28.473025 -22.898768 ...    0.000000   0.000000   \n",
       "18   -23.243730 -23.403430 -24.746574 -27.448420 ...    0.000000   0.000000   \n",
       "19   -27.444782 -26.563062 -28.344539 -30.682944 ...    0.000000   0.000000   \n",
       "20   -28.016156 -26.810886 -23.732390 -20.060123 ...    0.000000   0.000000   \n",
       "21   -26.033109 -25.890417 -29.243048 -29.504144 ...    0.000000   0.000000   \n",
       "22   -31.713522 -31.112697 -29.784670 -27.872223 ...    0.000000   0.000000   \n",
       "23   -29.637484 -27.181203 -27.820088 -31.960785 ...    0.000000   0.000000   \n",
       "24   -33.753916 -30.158459 -26.667678 -27.586738 ...    0.000000   0.000000   \n",
       "25   -29.281467 -25.486285 -26.955471 -30.582568 ...    0.000000   0.000000   \n",
       "26   -27.754079 -25.246368 -25.420599 -29.144560 ...    0.000000   0.000000   \n",
       "27   -34.475837 -30.805294 -29.276661 -26.802264 ...    0.000000   0.000000   \n",
       "28   -24.788177 -21.252485 -22.564457 -26.753336 ...    0.000000   0.000000   \n",
       "29   -28.610422 -31.311367 -30.791007 -30.147918 ...    0.000000   0.000000   \n",
       "...         ...        ...        ...        ... ...         ...        ...   \n",
       "4487 -67.128017 -67.128017 -67.128017 -67.128017 ...  -52.192277 -53.082673   \n",
       "4488 -59.319399 -59.590825 -59.591379 -59.675603 ...  -34.058435 -34.644343   \n",
       "4489 -54.677157 -54.677157 -54.677157 -54.677157 ...  -38.009244 -40.035804   \n",
       "4490 -59.849780 -59.849780 -59.863135 -60.327359 ...  -58.885912 -59.354939   \n",
       "4491 -55.382404 -55.439658 -55.337597 -54.012888 ...  -35.287239 -39.428942   \n",
       "4492 -44.552925 -44.552925 -44.552925 -44.552925 ...  -38.175252 -37.902636   \n",
       "4493 -43.489744 -46.490625 -50.799665 -50.240377 ...  -45.281609 -48.504020   \n",
       "4494 -57.332370 -57.332370 -57.332370 -57.332370 ...  -56.565868 -57.332370   \n",
       "4495 -56.402303 -55.341964 -55.211303 -56.189707 ...  -45.765619 -45.138881   \n",
       "4496 -64.678723 -64.678723 -64.678723 -64.678723 ...  -61.665689 -61.047234   \n",
       "4497 -65.562365 -65.562365 -65.562365 -65.562365 ...  -61.889744 -61.001034   \n",
       "4498 -68.056359 -67.975604 -67.535529 -67.833166 ...  -58.913939 -57.802619   \n",
       "4499 -65.356763 -65.356763 -65.356763 -65.356763 ...  -57.523709 -56.629023   \n",
       "4500 -45.194876 -45.194876 -45.194876 -45.194876 ...  -45.666244 -45.259188   \n",
       "4501 -52.044049 -52.044049 -52.044049 -52.044049 ...  -51.989357 -52.044049   \n",
       "4502 -60.420515 -59.816253 -60.189272 -60.110914 ...  -58.988811 -58.988811   \n",
       "4503 -57.077028 -56.940813 -56.940813 -57.228633 ...  -42.686466 -44.226132   \n",
       "4504 -63.942344 -63.942344 -63.942344 -63.942344 ...  -61.957350 -63.942344   \n",
       "4505 -71.407071 -71.407071 -71.407071 -71.407071 ...  -64.321623 -66.922372   \n",
       "4506 -64.968548 -64.968548 -64.968548 -67.252646 ...  -64.678076 -64.360786   \n",
       "4507 -55.767393 -55.767393 -55.767393 -55.767393 ...  -36.569010 -36.725955   \n",
       "4508 -73.548430 -71.061247 -71.375159 -73.176079 ...  -47.070428 -48.173410   \n",
       "4509 -66.626091 -66.020631 -66.533440 -64.211415 ...  -60.016013 -61.026796   \n",
       "4510 -64.448001 -64.448001 -64.448001 -64.244446 ...  -45.155677 -46.213197   \n",
       "4511 -53.286076 -52.388832 -52.388832 -52.399767 ...  -44.524053 -46.362766   \n",
       "4512 -69.567537 -69.567537 -69.567537 -69.567537 ...  -43.286208 -43.042348   \n",
       "4513 -56.128047 -55.966648 -55.947412 -55.989351 ...  -25.450151 -26.664525   \n",
       "4514 -53.054884 -53.054884 -53.054884 -53.054884 ...  -50.203255 -49.621696   \n",
       "4515 -64.206723 -64.206723 -64.206723 -64.206723 ...  -59.251821 -58.833817   \n",
       "4516 -52.199923 -52.218305 -52.633871 -51.629967 ...  -50.145131 -48.712166   \n",
       "\n",
       "            209        210        211        212        213        214  \\\n",
       "0      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "8      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "9      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "10     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "11     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "12     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "13     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "14     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "15     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "16     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "17     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "18     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "19     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "20     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "21     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "22     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "23     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "24     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "26     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "27     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "28     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "29     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4487 -54.695262 -52.384729 -53.175544 -54.981104 -54.078131 -54.207101   \n",
       "4488 -34.442063 -36.707547 -41.146307 -43.172390 -42.835244 -46.150078   \n",
       "4489 -39.657108 -40.550019 -43.559956 -45.444457 -46.496016 -46.470699   \n",
       "4490 -59.807379 -59.775160 -58.808937 -57.853232 -58.398109 -59.114060   \n",
       "4491 -41.273553 -40.047037 -40.112812 -43.898186 -46.512260 -45.556203   \n",
       "4492 -40.407236 -40.815793 -41.241603 -41.736607 -43.396698 -42.237670   \n",
       "4493 -50.357992 -44.687362 -43.194414 -46.666642 -50.128142 -50.941980   \n",
       "4494 -56.719102 -56.908147 -56.898329 -57.050586 -57.332370 -57.262080   \n",
       "4495 -45.866570 -44.450824 -45.075534 -47.864657 -49.669654 -52.591634   \n",
       "4496 -59.299474 -60.432158 -62.515880 -64.088474 -64.658195 -64.604102   \n",
       "4497 -61.759804 -62.241800 -62.069901 -61.062766 -58.563208 -60.640275   \n",
       "4498 -59.957985 -62.548852 -66.173967 -64.493243 -62.488814 -63.460311   \n",
       "4499 -57.543099 -58.982573 -57.795045 -57.904399 -58.457920 -60.506432   \n",
       "4500 -45.147653 -45.233620 -45.194876 -45.194876 -45.194876 -45.194876   \n",
       "4501 -52.044049 -52.044049 -52.044049 -52.044049 -52.044049 -52.044049   \n",
       "4502 -58.916401 -58.988811 -58.988811 -58.988811 -58.988811 -58.988811   \n",
       "4503 -44.101891 -43.651345 -45.493498 -47.759692 -50.536515 -51.336391   \n",
       "4504 -63.942344 -63.942344 -63.933362 -63.799121 -63.616188 -63.476149   \n",
       "4505 -70.591707 -69.530834 -66.970003 -66.873352 -68.084319 -70.437988   \n",
       "4506 -64.642809 -62.274782 -62.417866 -63.560128 -63.105106 -63.359077   \n",
       "4507 -38.104478 -38.821533 -38.295397 -36.559404 -36.244597 -35.140083   \n",
       "4508 -49.330655 -51.711174 -52.365458 -54.464719 -56.410372 -56.113212   \n",
       "4509 -61.306973 -61.006645 -60.669009 -62.031732 -64.399412 -64.815625   \n",
       "4510 -48.122823 -45.521263 -45.774197 -49.803602 -51.963733 -52.965988   \n",
       "4511 -46.383047 -47.492377 -51.348980 -51.252681 -50.509345 -49.606151   \n",
       "4512 -42.400162 -42.409806 -41.685644 -41.405289 -42.035714 -40.774790   \n",
       "4513 -28.591213 -29.936010 -29.608872 -31.826348 -36.193416 -37.252570   \n",
       "4514 -52.275230 -51.447833 -51.883657 -52.533490 -50.991376 -48.410666   \n",
       "4515 -57.978339 -61.298153 -58.773552 -60.140413 -63.886547 -63.014960   \n",
       "4516 -47.603032 -45.205415 -44.438685 -48.720497 -50.850345 -50.327162   \n",
       "\n",
       "            215  0.1  \n",
       "0      0.000000    0  \n",
       "1      0.000000    0  \n",
       "2      0.000000    0  \n",
       "3      0.000000    0  \n",
       "4      0.000000    0  \n",
       "5      0.000000    0  \n",
       "6      0.000000    0  \n",
       "7      0.000000    0  \n",
       "8      0.000000    0  \n",
       "9      0.000000    0  \n",
       "10     0.000000    0  \n",
       "11     0.000000    0  \n",
       "12     0.000000    0  \n",
       "13     0.000000    0  \n",
       "14     0.000000    0  \n",
       "15     0.000000    0  \n",
       "16     0.000000    0  \n",
       "17     0.000000    0  \n",
       "18     0.000000    0  \n",
       "19     0.000000    0  \n",
       "20     0.000000    0  \n",
       "21     0.000000    0  \n",
       "22     0.000000    0  \n",
       "23     0.000000    0  \n",
       "24     0.000000    0  \n",
       "25     0.000000    0  \n",
       "26     0.000000    0  \n",
       "27     0.000000    0  \n",
       "28     0.000000    0  \n",
       "29     0.000000    0  \n",
       "...         ...  ...  \n",
       "4487 -56.474811    5  \n",
       "4488 -45.851973    5  \n",
       "4489 -47.322224    5  \n",
       "4490 -58.564454    3  \n",
       "4491 -43.528693    3  \n",
       "4492 -41.635098    3  \n",
       "4493 -50.317816    3  \n",
       "4494 -57.332370    3  \n",
       "4495 -54.877643    3  \n",
       "4496 -64.560031    3  \n",
       "4497 -63.574741    3  \n",
       "4498 -64.412657    4  \n",
       "4499 -59.845687    4  \n",
       "4500 -45.194876    4  \n",
       "4501 -52.044049    0  \n",
       "4502 -58.988811    0  \n",
       "4503 -50.690862    1  \n",
       "4504 -63.391090    1  \n",
       "4505 -70.868711    1  \n",
       "4506 -63.284678    1  \n",
       "4507 -32.330563    1  \n",
       "4508 -54.474242    2  \n",
       "4509 -64.799419    6  \n",
       "4510 -52.242500    6  \n",
       "4511 -47.599135    6  \n",
       "4512 -38.137740    6  \n",
       "4513 -37.633020    6  \n",
       "4514 -47.317401    6  \n",
       "4515 -63.745278    6  \n",
       "4516 -48.915758    6  \n",
       "\n",
       "[4517 rows x 217 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"9_27_2018_5_53_pm_emotions_and_speakers.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 217, 32)           192       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 217, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 108, 64)           10304     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 108, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               442496    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 453,895\n",
      "Trainable params: 453,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in dataframe for additional training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x_train shape: (6035, 272)\n",
      "6035 train samples\n",
      "685 test samples\n"
     ]
    }
   ],
   "source": [
    "emotionsDf = pd.read_csv('emotionsDfV1.csv')\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "shuffledDf = shuffle(emotionsDf)\n",
    "\n",
    "divider = np.random.rand(len(shuffledDf)) < 0.9\n",
    "train = shuffledDf[divider]\n",
    "test = shuffledDf[~divider]\n",
    "\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabels = train.iloc[:, -1:]\n",
    "\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabels = test.iloc[:, -1:]\n",
    "\n",
    "x_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabels)\n",
    "x_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabels)\n",
    "\n",
    "#flattening the arrays\n",
    "y_train = np.hstack(y_train)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "#convert class vectors to binary class matrices.\n",
    "num_classes = 7\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('     x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train = np.expand_dims(x_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "# Create the model\n",
    "model =  models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "#modelv3.add(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some test data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1247\u001b[0;31m                 \u001b[0;34m'This model has never been called, thus its weights '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m                 \u001b[0;34m'have not yet been created, so no summary can be displayed. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m                 \u001b[0;34m'Build the model first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some test data)."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(32, 5, padding='same',input_shape=(272,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adadelta()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6035 samples, validate on 685 samples\n",
      "Epoch 1/100\n",
      "  96/6035 [..............................] - ETA: 2:23 - loss: 12.3684 - acc: 0.1667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ec392e39ef7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='Attempt7Architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "cnnhistory = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(cnnhistory.history['acc'])\n",
    "plt.plot(cnnhistory.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"Attempt7Acc.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(\"Attempt7Loss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Importing Data for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Actor_01\n",
      "1 Actor_02\n",
      "2 Actor_03\n",
      "3 Actor_04\n",
      "4 Actor_05\n",
      "5 Actor_06\n",
      "6 Actor_07\n",
      "7 Actor_08\n",
      "8 Actor_09\n",
      "9 Actor_10\n",
      "10 Actor_11\n",
      "11 Actor_12\n",
      "12 Actor_13\n",
      "13 Actor_14\n",
      "14 Actor_15\n",
      "15 Actor_16\n",
      "16 Actor_17\n",
      "17 Actor_18\n",
      "18 Actor_19\n",
      "19 Actor_20\n",
      "20 Actor_21\n",
      "21 Actor_22\n",
      "22 Actor_23\n",
      "23 Actor_24\n"
     ]
    }
   ],
   "source": [
    "actorlist = os.listdir('Audio')\n",
    "mydir = 'Audio/'\n",
    "mylist = os.listdir(mydir)\n",
    "actorlist.sort()\n",
    "\n",
    "feeling_list=[]\n",
    "mydir = 'Audio/'\n",
    "for actor in actorlist:\n",
    "    try:\n",
    "        mylist = os.listdir(mydir+actor)\n",
    "        mylist.sort()\n",
    "        for item in mylist:\n",
    "            \n",
    "            #neutral\n",
    "            if item[6:-16]=='01' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(5)\n",
    "            elif item[6:-16]=='01' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(5)\n",
    "            #calm\n",
    "            if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(5)\n",
    "            elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(5)\n",
    "            #happy\n",
    "            elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(3)\n",
    "            elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(3)\n",
    "            #sad\n",
    "            elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(4)\n",
    "            elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(4)\n",
    "            #angry\n",
    "            elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(0)\n",
    "            elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(0)\n",
    "            #fear\n",
    "            elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(1)\n",
    "            elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(1)\n",
    "            #disgust\n",
    "            if item[6:-16]=='07' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(2)\n",
    "            elif item[6:-16]=='07' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(2)\n",
    "            #surprise\n",
    "            if item[6:-16]=='08' and int(item[18:-4])%2==0:\n",
    "                feeling_list.append(6)\n",
    "            elif item[6:-16]=='08' and int(item[18:-4])%2==1:\n",
    "                feeling_list.append(6)\n",
    "                \n",
    "    except: pass\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#labels = pd.DataFrame(feeling_list)\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,actor in enumerate(actorlist):\n",
    "    print(index, actor)\n",
    "    try:\n",
    "        recordinglist = os.listdir('Audio/'+actor)\n",
    "        for index, recording in enumerate(recordinglist):\n",
    "            X, sample_rate = librosa.load('Audio/'+actor+'/'+recording, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "            sample_rate = np.array(sample_rate)\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                                sr=sample_rate, \n",
    "                                                n_mfcc=13),\n",
    "                            axis=0)\n",
    "            feature = mfccs\n",
    "            df.loc[bookmark] = [feature]\n",
    "            bookmark=bookmark+1\n",
    "    except: pass\n",
    "\n",
    "actorDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "\n",
    "#labeledDf = pd.concat([featuresDf, labels], axis=1)\n",
    "\n",
    "#named = labeledDf.rename(index=str, columns={\"0\":\"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/fear/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "fearDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#fearDf['label'] = \"fear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/angry/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "angryDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#angryDf['label'] = \"angry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/disgust/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "    sample_rate = np.array(sampling_rate)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                        sr=sample_rate, \n",
    "                                        n_mfcc=13),\n",
    "                    axis=0)\n",
    "    feature = mfccs\n",
    "    df.loc[bookmark] = [feature]\n",
    "    bookmark+=1\n",
    "disgustDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#disgustDf['label'] = \"disgust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/happy/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "happyDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#happyDf['label'] = \"happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/neutral/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "neutralDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#neutralDf['label'] = \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/surprise/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "surpriseDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#surpriseDf['label'] = \"surprise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/sad/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "sadDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#sadDf['label'] = \"sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/DC/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "dc_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        dc_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        dc_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        dc_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        dc_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        dc_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        dc_feeling_list.append('sad')\n",
    "    else: dc_feeling_list.append('surprise')\n",
    "    \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "#labels = pd.DataFrame(dc_feeling_list)\n",
    "dcDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#dcDf = pd.concat([dcDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/JE/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "je_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        je_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        je_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        je_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        je_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        je_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        je_feeling_list.append('sad')\n",
    "    else: je_feeling_list.append('surprise')\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "jeDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(je_feeling_list)\n",
    "#jeDf = pd.concat([jeDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/JK/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "jk_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        jk_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        jk_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        jk_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        jk_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        jk_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        jk_feeling_list.append('sad')\n",
    "    else: jk_feeling_list.append('surprise')\n",
    "    \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "jkDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(jk_feeling_list)\n",
    "#jkDf = pd.concat([jkDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioData/KL/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "kl_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    emotion = file[0]\n",
    "    \n",
    "    if emotion == 'a':\n",
    "        kl_feeling_list.append('angry')\n",
    "    elif emotion == 'd':\n",
    "        kl_feeling_list.append('disgust')\n",
    "    elif emotion == 'f':\n",
    "        kl_feeling_list.append('fear')\n",
    "    elif emotion == 'h':\n",
    "        kl_feeling_list.append('happy')\n",
    "    elif emotion == 'n':\n",
    "        kl_feeling_list.append('neutral')\n",
    "    elif emotion == 's' and file[1] == 'a':\n",
    "        kl_feeling_list.append('sad')\n",
    "    else: kl_feeling_list.append('surprise')\n",
    "        \n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "    except:\n",
    "        pass\n",
    "klDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labels = pd.DataFrame(kl_feeling_list)\n",
    "#klDf = pd.concat([klDf, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/AudioWAV/\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "wav_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    try:\n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "        emotion = file[9:12] \n",
    "        \n",
    "        if emotion == \"ANG\":\n",
    "            wav_feeling_list.append(\"angry\")\n",
    "        elif emotion == \"DIS\":\n",
    "            wav_feeling_list.append(\"disgust\")\n",
    "        elif emotion == \"FEA\":\n",
    "            wav_feeling_list.append(\"fear\")\n",
    "        elif emotion == \"HAP\":\n",
    "            wav_feeling_list.append(\"happy\")\n",
    "        elif emotion == \"NEU\":\n",
    "            wav_feeling_list.append(\"neutral\")\n",
    "        elif emotion == \"SAD\":\n",
    "            wav_feeling_list.append(\"sad\")\n",
    "        else:\n",
    "            print(\"      \", emotion)\n",
    "    except:\n",
    "        pass\n",
    "wavDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labelsDf = pd.DataFrame(feeling_list)\n",
    "#wavDf = pd.concat([wavDf, labelsDf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = \"./training_audio_files/emodb/wav\"\n",
    "trainFileList = os.listdir(trainDir)\n",
    "trainFileList.sort()\n",
    "emo_feeling_list = []\n",
    "\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for file in trainFileList:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        X, sampling_rate = librosa.load(trainDir+file, duration=5.0)\n",
    "        sample_rate = np.array(sampling_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark+=1\n",
    "        \n",
    "        emotion = file[5]\n",
    "        if emotion == 'A':\n",
    "            emo_feeling_list.append(\"fear\")\n",
    "        elif emotion == 'W':\n",
    "            emo_feeling_list.append(\"angry\")\n",
    "        elif emotion == 'L':\n",
    "            emo_feeling_list.append(\"bored\")\n",
    "        elif emotion == 'E':\n",
    "            emo_feeling_list.append(\"disgust\")\n",
    "        elif emotion == 'F':\n",
    "            emo_feeling_list.append(\"happy\")\n",
    "        elif emotion == 'T':\n",
    "            emo_feeling_list.append(\"sad\")\n",
    "        elif emotion == 'N':\n",
    "            emo_feeling_list.append(\"neutral\")\n",
    "        else:\n",
    "            print(\"error\", emotion)\n",
    "    except:\n",
    "        pass\n",
    "emoDf = pd.DataFrame(df['feature'].values.tolist())\n",
    "#labelDf = pd.DataFrame(feeling_list)\n",
    "#emoDf = pd.concat([emoDf, labelDf], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat2 = pd.concat([dcDf,jeDf, jkDf, klDf])\n",
    "concatenatedDf = pd.concat([angryDf, fearDf, disgustDf, happyDf, sadDf, neutralDf, surpriseDf, concat2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a list of emotion labels for each audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_feeling_list = []\n",
    "for file in range(len(angryDf)):\n",
    "    compiled_feeling_list.append(0)\n",
    "for file in range(len(fearDf)):\n",
    "    compiled_feeling_list.append(1)\n",
    "for file in range(len(disgustDf)):\n",
    "    compiled_feeling_list.append(2)\n",
    "for file in range(len(happyDf)):\n",
    "    compiled_feeling_list.append(3)\n",
    "for file in range(len(sadDf)):\n",
    "    compiled_feeling_list.append(4)\n",
    "for file in range(len(neutralDf)):\n",
    "    compiled_feeling_list.append(5)\n",
    "for file in range(len(surpriseDf)):\n",
    "    compiled_feeling_list.append(6)\n",
    "\n",
    "dcjejkkl_feeling_list = dc_feeling_list + je_feeling_list + jk_feeling_list + kl_feeling_list\n",
    "for emo in range(len(dcjejkkl_feeling_list)):\n",
    "    if dcjejkkl_feeling_list[emo] == \"angry\":\n",
    "        compiled_feeling_list.append(0)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"fear\":\n",
    "        compiled_feeling_list.append(1)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"disgust\":\n",
    "        compiled_feeling_list.append(2)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"happy\":\n",
    "        compiled_feeling_list.append(3)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"sad\":\n",
    "        compiled_feeling_list.append(4)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"neutral\":\n",
    "        compiled_feeling_list.append(5)\n",
    "    elif dcjejkkl_feeling_list[emo] == \"surprise\":\n",
    "        compiled_feeling_list.append(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pandas DataFrame with emotion labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feeling_list) == len(actorDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_feeling_list += feeling_list\n",
    "concatenatedDf = pd.concat([concatenatedDf, actorDf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelDf = pd.DataFrame(compiled_feeling_list)\n",
    "\n",
    "concatenatedDf = concatenatedDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf = pd.concat([concatenatedDf, labelDf], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf = concatenatedDf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exported the labeled Pandas DataFrame for easier import of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenatedDf.to_csv(\"9_24_2018_3_02_pm_emotions_and_speakers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4068, 217)\n",
      "4068 train samples\n",
      "449 test samples\n"
     ]
    }
   ],
   "source": [
    "emotionsDf = pd.read_csv(\"9_24_2018_3_02_pm_emotions_and_speakers.csv\")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "shuffledDf = shuffle(emotionsDf)\n",
    "\n",
    "divider = np.random.rand(len(shuffledDf)) < 0.9\n",
    "train = shuffledDf[divider]\n",
    "test = shuffledDf[~divider]\n",
    "\n",
    "trainfeatures = train.iloc[:, :-1]\n",
    "trainlabels = train.iloc[:, -1:]\n",
    "\n",
    "testfeatures = test.iloc[:, :-1]\n",
    "testlabels = test.iloc[:, -1:]\n",
    "\n",
    "x_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabels)\n",
    "x_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabels)\n",
    "\n",
    "#flattening the arrays\n",
    "y_train = np.hstack(y_train)\n",
    "y_test = np.hstack(y_test)\n",
    "\n",
    "#convert class vectors to binary class matrices.\n",
    "num_classes = 7\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train = np.expand_dims(x_train, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, 5, padding='same',input_shape=(217,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(128, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# model.add(Conv1D(256, 5, padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adadelta()\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4068 samples, validate on 449 samples\n",
      "Epoch 1/100\n",
      "4068/4068 [==============================] - 25s 6ms/step - loss: 11.0639 - acc: 0.2554 - val_loss: 7.9899 - val_acc: 0.4588\n",
      "Epoch 2/100\n",
      "4068/4068 [==============================] - 24s 6ms/step - loss: 5.1735 - acc: 0.3451 - val_loss: 1.5462 - val_acc: 0.4343\n",
      "Epoch 3/100\n",
      "4068/4068 [==============================] - 25s 6ms/step - loss: 1.4957 - acc: 0.4287 - val_loss: 1.1849 - val_acc: 0.5568\n",
      "Epoch 4/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 1.3494 - acc: 0.4749 - val_loss: 1.1800 - val_acc: 0.5412\n",
      "Epoch 5/100\n",
      "4068/4068 [==============================] - 22s 5ms/step - loss: 1.2712 - acc: 0.5081 - val_loss: 1.1516 - val_acc: 0.5412\n",
      "Epoch 6/100\n",
      "4068/4068 [==============================] - 26s 6ms/step - loss: 1.1960 - acc: 0.5315 - val_loss: 1.0650 - val_acc: 0.6013\n",
      "Epoch 7/100\n",
      "4068/4068 [==============================] - 26s 6ms/step - loss: 1.1470 - acc: 0.5457 - val_loss: 1.0032 - val_acc: 0.5924\n",
      "Epoch 8/100\n",
      "4068/4068 [==============================] - 25s 6ms/step - loss: 1.1052 - acc: 0.5656 - val_loss: 1.0427 - val_acc: 0.5523\n",
      "Epoch 9/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 1.0858 - acc: 0.5632 - val_loss: 0.9083 - val_acc: 0.6548\n",
      "Epoch 10/100\n",
      "4068/4068 [==============================] - 26s 7ms/step - loss: 1.0674 - acc: 0.5765 - val_loss: 0.8773 - val_acc: 0.6659\n",
      "Epoch 11/100\n",
      "4068/4068 [==============================] - 26s 7ms/step - loss: 1.0428 - acc: 0.5811 - val_loss: 0.9186 - val_acc: 0.6637\n",
      "Epoch 12/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 1.0235 - acc: 0.5885 - val_loss: 1.0572 - val_acc: 0.5501\n",
      "Epoch 13/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 1.0152 - acc: 0.5993 - val_loss: 1.1238 - val_acc: 0.5768\n",
      "Epoch 14/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9966 - acc: 0.6042 - val_loss: 0.8506 - val_acc: 0.6659\n",
      "Epoch 15/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9934 - acc: 0.6148 - val_loss: 0.9447 - val_acc: 0.6080\n",
      "Epoch 16/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9717 - acc: 0.6177 - val_loss: 0.8425 - val_acc: 0.6570\n",
      "Epoch 17/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9534 - acc: 0.6229 - val_loss: 0.8140 - val_acc: 0.6949\n",
      "Epoch 18/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9380 - acc: 0.6323 - val_loss: 0.8017 - val_acc: 0.6949\n",
      "Epoch 19/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.9263 - acc: 0.6342 - val_loss: 0.8090 - val_acc: 0.6904\n",
      "Epoch 20/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.9194 - acc: 0.6377 - val_loss: 0.8202 - val_acc: 0.6904\n",
      "Epoch 21/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.9185 - acc: 0.6433 - val_loss: 0.7587 - val_acc: 0.6993\n",
      "Epoch 22/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.9051 - acc: 0.6465 - val_loss: 0.8773 - val_acc: 0.6414\n",
      "Epoch 23/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.9001 - acc: 0.6426 - val_loss: 0.8514 - val_acc: 0.6548\n",
      "Epoch 24/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8773 - acc: 0.6524 - val_loss: 1.0014 - val_acc: 0.6570\n",
      "Epoch 25/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8832 - acc: 0.6573 - val_loss: 0.7434 - val_acc: 0.7016\n",
      "Epoch 26/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8634 - acc: 0.6586 - val_loss: 0.7788 - val_acc: 0.6971\n",
      "Epoch 27/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8712 - acc: 0.6586 - val_loss: 0.7504 - val_acc: 0.7016\n",
      "Epoch 28/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8696 - acc: 0.6566 - val_loss: 0.7520 - val_acc: 0.7016\n",
      "Epoch 29/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8563 - acc: 0.6583 - val_loss: 0.7325 - val_acc: 0.7082\n",
      "Epoch 30/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8511 - acc: 0.6630 - val_loss: 0.7546 - val_acc: 0.6949\n",
      "Epoch 31/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8656 - acc: 0.6595 - val_loss: 0.7446 - val_acc: 0.7105\n",
      "Epoch 32/100\n",
      "4068/4068 [==============================] - 29s 7ms/step - loss: 0.8540 - acc: 0.6662 - val_loss: 0.7308 - val_acc: 0.7060\n",
      "Epoch 33/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8588 - acc: 0.6632 - val_loss: 0.8746 - val_acc: 0.6570\n",
      "Epoch 34/100\n",
      "4068/4068 [==============================] - 29s 7ms/step - loss: 0.8431 - acc: 0.6647 - val_loss: 0.7344 - val_acc: 0.7060\n",
      "Epoch 35/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8290 - acc: 0.6664 - val_loss: 0.7456 - val_acc: 0.7016\n",
      "Epoch 36/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8561 - acc: 0.6652 - val_loss: 0.7370 - val_acc: 0.7060\n",
      "Epoch 37/100\n",
      "4068/4068 [==============================] - 29s 7ms/step - loss: 0.8235 - acc: 0.6701 - val_loss: 0.7298 - val_acc: 0.7016\n",
      "Epoch 38/100\n",
      "4068/4068 [==============================] - 25s 6ms/step - loss: 0.8359 - acc: 0.6716 - val_loss: 0.7401 - val_acc: 0.7082\n",
      "Epoch 39/100\n",
      "4068/4068 [==============================] - 21s 5ms/step - loss: 0.8298 - acc: 0.6708 - val_loss: 0.7345 - val_acc: 0.7038\n",
      "Epoch 40/100\n",
      "4068/4068 [==============================] - 22s 6ms/step - loss: 0.8286 - acc: 0.6696 - val_loss: 0.7273 - val_acc: 0.7060\n",
      "Epoch 41/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8226 - acc: 0.6699 - val_loss: 0.7312 - val_acc: 0.7016\n",
      "Epoch 42/100\n",
      "4068/4068 [==============================] - 25s 6ms/step - loss: 0.8213 - acc: 0.6713 - val_loss: 0.7481 - val_acc: 0.7038\n",
      "Epoch 43/100\n",
      "4068/4068 [==============================] - 23s 6ms/step - loss: 0.8160 - acc: 0.6723 - val_loss: 0.7392 - val_acc: 0.7016\n",
      "Epoch 44/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8122 - acc: 0.6748 - val_loss: 0.7331 - val_acc: 0.7082\n",
      "Epoch 45/100\n",
      "4068/4068 [==============================] - 28s 7ms/step - loss: 0.8290 - acc: 0.6718 - val_loss: 0.7188 - val_acc: 0.7105\n",
      "Epoch 46/100\n",
      "4068/4068 [==============================] - 22s 6ms/step - loss: 0.8102 - acc: 0.6716 - val_loss: 0.7899 - val_acc: 0.6860\n",
      "Epoch 47/100\n",
      "4068/4068 [==============================] - 27s 7ms/step - loss: 0.8083 - acc: 0.6743 - val_loss: 0.7327 - val_acc: 0.7082\n",
      "Epoch 48/100\n",
      "4068/4068 [==============================] - 38s 9ms/step - loss: 0.8132 - acc: 0.6723 - val_loss: 0.7250 - val_acc: 0.7060\n",
      "Epoch 49/100\n",
      "4068/4068 [==============================] - 39s 10ms/step - loss: 0.8036 - acc: 0.6807 - val_loss: 0.7229 - val_acc: 0.7127\n",
      "Epoch 50/100\n",
      "4068/4068 [==============================] - 38s 9ms/step - loss: 0.8077 - acc: 0.6755 - val_loss: 0.7687 - val_acc: 0.6971\n",
      "Epoch 51/100\n",
      "4068/4068 [==============================] - 36s 9ms/step - loss: 0.8225 - acc: 0.6733 - val_loss: 0.7260 - val_acc: 0.7060\n",
      "Epoch 52/100\n",
      "4068/4068 [==============================] - 34s 8ms/step - loss: 0.8045 - acc: 0.6822 - val_loss: 0.7224 - val_acc: 0.7082\n",
      "Epoch 53/100\n",
      "4068/4068 [==============================] - 33s 8ms/step - loss: 0.7921 - acc: 0.6785 - val_loss: 0.8007 - val_acc: 0.6860\n",
      "Epoch 54/100\n",
      "4068/4068 [==============================] - 32s 8ms/step - loss: 0.7932 - acc: 0.6799 - val_loss: 0.7261 - val_acc: 0.7082\n",
      "Epoch 55/100\n",
      "4068/4068 [==============================] - 36s 9ms/step - loss: 0.8143 - acc: 0.6758 - val_loss: 0.7616 - val_acc: 0.6993\n",
      "Epoch 56/100\n",
      "4068/4068 [==============================] - 52s 13ms/step - loss: 0.8079 - acc: 0.6790 - val_loss: 0.7300 - val_acc: 0.7082\n",
      "Epoch 57/100\n",
      " 160/4068 [>.............................] - ETA: 1:15 - loss: 0.9388 - acc: 0.6438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b405b5b29d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "cnnhistory = model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnnhistory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2c5a53dfaa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnnhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnnhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnnhistory' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#sigmoid\n",
    "plt.plot(cnnhistory.history['acc'])\n",
    "plt.plot(cnnhistory.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain model2.h (9_24_2018_1_43_pm_emotions_and_speakers.csv)  with J. Schwoebel's JSON data\n",
    "### Completely rebuild model with J. S. JSON data and  9_24_2018_3_03_pm_emotions_and_speakers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
